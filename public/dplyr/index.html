<!DOCTYPE html>
<html>
<head>
  <script>
    theBaseUrl = location.origin + "/";
  </script>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width,user-scalable=no,initial-scale=1,maximum-scale=1">
  <title></title>
  <meta name="generator" content="Hugo 0.29" />

  
  <meta name="description" content="An R interface to Spark">
  
  <link rel="canonical" href="/dplyr/">
  

  <meta property="og:url" content="/dplyr/">
  <meta property="og:title" content="sparklyr">
  <meta name="apple-mobile-web-app-title" content="sparklyr">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

  <style>
    @font-face {
      font-family: 'Icon';
      src: url('fonts/icon.eot?52m981');
      src: url('fonts/icon.eot?#iefix52m981')
      format('embedded-opentype'),
      url('fonts/icon.woff?52m981')
      format('woff'),
      url('fonts/icon.ttf?52m981')
      format('truetype'),
      url('fonts/icon.svg?52m981#icon')
      format('svg');
      font-weight: normal;
      font-style: normal;
    }
  </style>


  <link rel="stylesheet" href="/css/style.css">
  <link rel="stylesheet" href="/css/site-styles.css">

  <script src="/js/vendor.js"></script>

  <script src="/js/app.js"></script>
  
  <link rel="shortcut icon" href="/images/favicon.png">

  
</head>
<body>


<div class="single-page">
  
<script type="text/javascript">
(function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){
(w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);
e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);
})(window,document,'script','//s.swiftypecdn.com/install/v2/st.js','_st');

_st('install','ubj6WcBvA61Exph85z7Q','2.0.0');
</script>


<nav data-gumshoe-header aria-label="Header" id="header" class="top-menu">
  <div class="left">
     <a href = "/" data-parenturl="" class="top-menu-item site-title">sparklyr</a>
     <span class="logo-from">from</span>
     <a href="/">
      <div id="logo" class="logo"></div>
    </a>
  </div>


  <div class="right">
    <div class="top-menu-items" id="top-menu-items">
        <a href="/dplyr" data-parenturl="/dplyr" class="top-menu-item">dplyr</a>
        <a href="/mlib" data-parenturl="/mlib" class="top-menu-item">MLib</a>
        <a href="/extensions" data-parenturl="/extensions" class="top-menu-item">Extensions</a>
        <a href="/news" data-parenturl="/news" class="top-menu-item">News</a>
        <a href="/reference" data-parenturl="/reference" class="top-menu-item">Reference</a>
        <a href="https://github.com/rstudio/sparklyr" data-parenturl="" class="top-menu-item" ><i class="fa fa-github fa-2x" aria-hidden="true"></i></a>
    </div>


    <div class="search-button" aria-hidden="true">
      <i class="fa fa-lg fa-search"></i>
    </div>


  </div>
</nav>

<nav aria-label="Header" id="mobile-header">
  <a href = "/">sparklyr</a>
  <div class="right">
    <a href="https://github.com/rstudio/sparklyr" class="github-logo">
      <i class="fa fa-lg fa-github" aria-hidden="true"></i>
    </a>
    <div class="hamburger">
      <i class="fa fa-lg fa-bars" aria-hidden="true"></i>
    </div>

  </div>

</nav>

<div id="mobile-menu-container">
<ul id="mobile-menu">
  
    <li>
      <a href="">Using sparklyr</a>
       <i class="fa fa-chevron-right" aria-hidden="true"></i>
    </li>
    <ul>
    
      <li>
        <a href="/guides/connections/">Getting Started</a>
        
      </li>
      
    
      <li>
        <a href="/dplyr/">Manipulating data</a>
        
      </li>
      
    
      <li>
        <a href="/mlib/">Machine Learning</a>
        
      </li>
      
    
      <li>
        <a href="/guides/caching/">Understanding Caching</a>
        
      </li>
      
    
      <li>
        <a href="/deployment/">Deployment Options</a>
        
      </li>
      
    
    </ul>
  
    <li>
      <a href="">Guides</a>
       <i class="fa fa-chevron-right" aria-hidden="true"></i>
    </li>
    <ul>
    
      <li>
        <a href="/guides/distributed-r/">Distributed R</a>
        
      </li>
      
    
      <li>
        <a href="/guides/data-lakes/">Data Lakes</a>
        
      </li>
      
    
      <li>
        <a href="/extensions/">Extend sparklyr</a>
        
      </li>
      
    
      <li>
        <a href="/guides/pipelines">ML Pipelines</a>
        
      </li>
      
    
      <li>
        <a href="/guides/textmining">Text mining</a>
        
      </li>
      
    
      <li>
        <a href="/guides/h2o">Using H2O</a>
        
      </li>
      
    
    </ul>
  
    <li>
      <a href="/examples/">Deployment Examples</a>
       <i class="fa fa-chevron-right" aria-hidden="true"></i>
    </li>
    <ul>
    
      <li>
        <a href="/examples/stand-alone-aws/">Standalone cluster</a>
        
      </li>
      
    
      <li>
        <a href="/examples/yarn-cluster-emr/">YARN cluster</a>
        
      </li>
      
    
      <li>
        <a href="/examples/cloudera-aws/">Cloudera cluster</a>
        
      </li>
      
    
    </ul>
  
    <li>
      <a href="/reference/">Reference</a>
       
    </li>
    <ul>
    
    </ul>
  
</ul>

</div>

<div id="search-bar" class="search-bar">
  <p class="search-bar__icon"><i class="fa fa-lg fa-search"></i> </p>
  <div class="search-bar__input">
      <input type="text" name="search" class="st-default-search-input">
  </div>
  <div class="search-bar__exit">
    <i class="fa fa-lg fa-times"></i>
  </div>

  <div class="inline-search-results">
    <ul>

    </ul>
  </div>
</div>


</div>



<div class="page documentation">
    <div class="side-menu" id="side-menu">
    
    
  
    

        <a href="" class="side-menu__item__link">
          <img class="side-menu__item__link__icon" src="/images/icons/block-retina.png" alt="">
          <p class="side-menu__item__link__text">Using sparklyr</p>
        </a>

        <ul class="side-menu__sub">
          
            <li class="side-menu__sub__item ">
              <a id="menu-link-/guides/connections/" class="side-menu__sub__item__text" href="/guides/connections/" data-url="/guides/connections/">Getting Started</a>
            </li>
          
            <li class="side-menu__sub__item  active ">
              <a id="menu-link-/dplyr/" class="side-menu__sub__item__text" href="/dplyr/" data-url="/dplyr/">Manipulating data</a>
            </li>
          
            <li class="side-menu__sub__item ">
              <a id="menu-link-/mlib/" class="side-menu__sub__item__text" href="/mlib/" data-url="/mlib/">Machine Learning</a>
            </li>
          
            <li class="side-menu__sub__item ">
              <a id="menu-link-/guides/caching/" class="side-menu__sub__item__text" href="/guides/caching/" data-url="/guides/caching/">Understanding Caching</a>
            </li>
          
            <li class="side-menu__sub__item ">
              <a id="menu-link-/deployment/" class="side-menu__sub__item__text" href="/deployment/" data-url="/deployment/">Deployment Options</a>
            </li>
          
        </ul>
          

    

        <a href="" class="side-menu__item__link">
          <img class="side-menu__item__link__icon" src="/images/icons/block-retina.png" alt="">
          <p class="side-menu__item__link__text">Guides</p>
        </a>

        <ul class="side-menu__sub">
          
            <li class="side-menu__sub__item ">
              <a id="menu-link-/guides/distributed-r/" class="side-menu__sub__item__text" href="/guides/distributed-r/" data-url="/guides/distributed-r/">Distributed R</a>
            </li>
          
            <li class="side-menu__sub__item ">
              <a id="menu-link-/guides/data-lakes/" class="side-menu__sub__item__text" href="/guides/data-lakes/" data-url="/guides/data-lakes/">Data Lakes</a>
            </li>
          
            <li class="side-menu__sub__item ">
              <a id="menu-link-/extensions/" class="side-menu__sub__item__text" href="/extensions/" data-url="/extensions/">Extend sparklyr</a>
            </li>
          
            <li class="side-menu__sub__item ">
              <a id="menu-link-/guides/pipelines" class="side-menu__sub__item__text" href="/guides/pipelines" data-url="/guides/pipelines">ML Pipelines</a>
            </li>
          
            <li class="side-menu__sub__item ">
              <a id="menu-link-/guides/textmining" class="side-menu__sub__item__text" href="/guides/textmining" data-url="/guides/textmining">Text mining</a>
            </li>
          
            <li class="side-menu__sub__item ">
              <a id="menu-link-/guides/h2o" class="side-menu__sub__item__text" href="/guides/h2o" data-url="/guides/h2o">Using H2O</a>
            </li>
          
        </ul>
          

    

        <a href="/examples/" class="side-menu__item__link">
          <img class="side-menu__item__link__icon" src="/images/icons/block-retina.png" alt="">
          <p class="side-menu__item__link__text">Deployment Examples</p>
        </a>

        <ul class="side-menu__sub">
          
            <li class="side-menu__sub__item ">
              <a id="menu-link-/examples/stand-alone-aws/" class="side-menu__sub__item__text" href="/examples/stand-alone-aws/" data-url="/examples/stand-alone-aws/">Standalone cluster</a>
            </li>
          
            <li class="side-menu__sub__item ">
              <a id="menu-link-/examples/yarn-cluster-emr/" class="side-menu__sub__item__text" href="/examples/yarn-cluster-emr/" data-url="/examples/yarn-cluster-emr/">YARN cluster</a>
            </li>
          
            <li class="side-menu__sub__item ">
              <a id="menu-link-/examples/cloudera-aws/" class="side-menu__sub__item__text" href="/examples/cloudera-aws/" data-url="/examples/cloudera-aws/">Cloudera cluster</a>
            </li>
          
        </ul>
          

    

        <a href="/reference/" class="side-menu__item__link">
          <img class="side-menu__item__link__icon" src="/images/icons/block-retina.png" alt="">
          <p class="side-menu__item__link__text">Reference</p>
        </a>

        <ul class="side-menu__sub">
          
        </ul>
          

    
    
    </div>
    <div class="content">

      <h1 class="content-header"> </h1>

      <div class="markdowned">
      <div class="doc-page">
    
      <div class="doc-page-index">
      <ul id="gumshoe-container" data-gumshoe>
      </ul>
      </div>
  
      <div class="doc-page-body">  
        

<h1 id="manipulating-data-with-dplyr">Manipulating Data with dplyr</h1>

<h2 id="overview">Overview</h2>

<p><a href="https://cran.r-project.org/web/packages/dplyr/index.html"><strong>dplyr</strong></a> is
an R package for working with structured data both in and outside of R.
dplyr makes data manipulation for R users easy, consistent, and
performant. With dplyr as an interface to manipulating Spark DataFrames,
you can:</p>

<ul>
<li>Select, filter, and aggregate data</li>
<li>Use window functions (e.g. for sampling)</li>
<li>Perform joins on DataFrames</li>
<li>Collect data from Spark into R</li>
</ul>

<p>Statements in dplyr can be chained together using pipes defined by the
<a href="https://cran.r-project.org/web/packages/magrittr/vignettes/magrittr.html">magrittr</a>
R package. dplyr also supports <a href="https://cran.r-project.org/web/packages/dplyr/vignettes/nse.html">non-standard
evalution</a>
of its arguments. For more information on dplyr, see the
<a href="https://cran.r-project.org/web/packages/dplyr/vignettes/introduction.html">introduction</a>,
a guide for connecting to
<a href="https://cran.r-project.org/web/packages/dplyr/vignettes/databases.html">databases</a>,
and a variety of
<a href="https://cran.r-project.org/web/packages/dplyr/index.html">vignettes</a>.</p>

<h2 id="reading-data">Reading Data</h2>

<p>You can read data into Spark DataFrames using the following
functions:</p>

<table>
<thead>
<tr>
<th>Function</th>
<th>Description</th>
</tr>
</thead>

<tbody>
<tr>
<td><a href="/reference/spark_read_csv/"><code>spark_read_csv</code></a></td>
<td>Reads a CSV file and provides a data source compatible with dplyr</td>
</tr>

<tr>
<td><a href="/reference/spark_read_json/"><code>spark_read_json</code></a></td>
<td>Reads a JSON file and provides a data source compatible with dplyr</td>
</tr>

<tr>
<td><a href="/reference/spark_read_parquet/"><code>spark_read_parquet</code></a></td>
<td>Reads a parquet file and provides a data source compatible with dplyr</td>
</tr>
</tbody>
</table>

<p>Regardless of the format of your data, Spark supports reading data from
a variety of different data sources. These include data stored on HDFS
(<code>hdfs://</code> protocol), Amazon S3 (<code>s3n://</code> protocol), or local files
available to the Spark worker nodes (<code>file://</code> protocol)</p>

<p>Each of these functions returns a reference to a Spark DataFrame which
can be used as a dplyr table (<code>tbl</code>).</p>

<h3 id="flights-data">Flights Data</h3>

<p>This guide will demonstrate some of the basic data manipulation verbs of
dplyr by using data from the <code>nycflights13</code> R package. This package
contains data for all 336,776 flights departing New York City in 2013.
It also includes useful metadata on airlines, airports, weather, and
planes. The data comes from the US <a href="http://www.transtats.bts.gov/DatabaseInfo.asp?DB_ID=120&amp;Link=0">Bureau of Transportation
Statistics</a>,
and is documented in <code>?nycflights13</code></p>

<p>Connect to the cluster and copy the flights data using the <code>copy_to</code>
function. Caveat: The flight data in <code>nycflights13</code> is convenient for
dplyr demonstrations because it is small, but in practice large data
should rarely be copied directly from R objects.</p>

<pre><code class="language-r">library(sparklyr)
library(dplyr)
library(nycflights13)
library(ggplot2)

sc &lt;- spark_connect(master=&quot;local&quot;)
flights &lt;- copy_to(sc, flights, &quot;flights&quot;)
airlines &lt;- copy_to(sc, airlines, &quot;airlines&quot;)
src_tbls(sc)
</code></pre>

<pre><code>## [1] &quot;airlines&quot; &quot;flights&quot;
</code></pre>

<h2 id="dplyr-verbs">dplyr Verbs</h2>

<p>Verbs are dplyr commands for manipulating data. When connected to a
Spark DataFrame, dplyr translates the commands into Spark SQL
statements. Remote data sources use exactly the same five verbs as local
data sources. Here are the five verbs with their corresponding SQL
commands:</p>

<ul>
<li><code>select</code> ~ <code>SELECT</code></li>
<li><code>filter</code> ~ <code>WHERE</code></li>
<li><code>arrange</code> ~ <code>ORDER</code></li>
<li><code>summarise</code> ~ <code>aggregators: sum, min, sd, etc.</code></li>
<li><code>mutate</code> ~ <code>operators: +, *, log, etc.</code></li>
</ul>

<!-- end list -->

<pre><code class="language-r">select(flights, year:day, arr_delay, dep_delay)
</code></pre>

<pre><code>## # Source: lazy query [?? x 5]
## # Database: spark_connection
##     year month   day arr_delay dep_delay
##    &lt;int&gt; &lt;int&gt; &lt;int&gt;     &lt;dbl&gt;     &lt;dbl&gt;
##  1  2013     1     1     11.0       2.00
##  2  2013     1     1     20.0       4.00
##  3  2013     1     1     33.0       2.00
##  4  2013     1     1    -18.0      -1.00
##  5  2013     1     1    -25.0      -6.00
##  6  2013     1     1     12.0      -4.00
##  7  2013     1     1     19.0      -5.00
##  8  2013     1     1    -14.0      -3.00
##  9  2013     1     1    - 8.00     -3.00
## 10  2013     1     1      8.00     -2.00
## # ... with more rows
</code></pre>

<pre><code class="language-r">filter(flights, dep_delay &gt; 1000)
</code></pre>

<pre><code>## # Source: lazy query [?? x 19]
## # Database: spark_connection
##    year month   day dep_t~ sche~ dep_~ arr_~ sche~ arr_~ carr~ flig~ tail~
##   &lt;int&gt; &lt;int&gt; &lt;int&gt;  &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt;
## 1  2013     1     9    641   900  1301  1242  1530  1272 HA       51 N384~
## 2  2013     1    10   1121  1635  1126  1239  1810  1109 MQ     3695 N517~
## 3  2013     6    15   1432  1935  1137  1607  2120  1127 MQ     3535 N504~
## 4  2013     7    22    845  1600  1005  1044  1815   989 MQ     3075 N665~
## 5  2013     9    20   1139  1845  1014  1457  2210  1007 AA      177 N338~
## # ... with 7 more variables: origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;,
## #   distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dbl&gt;
</code></pre>

<pre><code class="language-r">arrange(flights, desc(dep_delay))
</code></pre>

<pre><code>## # Source: table&lt;flights&gt; [?? x 19]
## # Database: spark_connection
## # Ordered by: desc(dep_delay)
##     year month   day dep_~ sche~ dep_~ arr_~ sche~ arr_~ carr~ flig~ tail~
##    &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt;
##  1  2013     1     9   641   900  1301  1242  1530  1272 HA       51 N384~
##  2  2013     6    15  1432  1935  1137  1607  2120  1127 MQ     3535 N504~
##  3  2013     1    10  1121  1635  1126  1239  1810  1109 MQ     3695 N517~
##  4  2013     9    20  1139  1845  1014  1457  2210  1007 AA      177 N338~
##  5  2013     7    22   845  1600  1005  1044  1815   989 MQ     3075 N665~
##  6  2013     4    10  1100  1900   960  1342  2211   931 DL     2391 N959~
##  7  2013     3    17  2321   810   911   135  1020   915 DL     2119 N927~
##  8  2013     6    27   959  1900   899  1236  2226   850 DL     2007 N376~
##  9  2013     7    22  2257   759   898   121  1026   895 DL     2047 N671~
## 10  2013    12     5   756  1700   896  1058  2020   878 AA      172 N5DM~
## # ... with more rows, and 7 more variables: origin &lt;chr&gt;, dest &lt;chr&gt;,
## #   air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour
## #   &lt;dbl&gt;
</code></pre>

<pre><code class="language-r">summarise(flights, mean_dep_delay = mean(dep_delay))
</code></pre>

<pre><code>## Warning: Missing values are always removed in SQL.
## Use `AVG(x, na.rm = TRUE)` to silence this warning

## # Source: lazy query [?? x 1]
## # Database: spark_connection
##   mean_dep_delay
##            &lt;dbl&gt;
## 1           12.6
</code></pre>

<pre><code class="language-r">mutate(flights, speed = distance / air_time * 60)
</code></pre>

<pre><code>## # Source: lazy query [?? x 20]
## # Database: spark_connection
##     year month   day dep_t~ sched_~ dep_d~ arr_~ sched~ arr_d~ carr~ flig~
##    &lt;int&gt; &lt;int&gt; &lt;int&gt;  &lt;int&gt;   &lt;int&gt;  &lt;dbl&gt; &lt;int&gt;  &lt;int&gt;  &lt;dbl&gt; &lt;chr&gt; &lt;int&gt;
##  1  2013     1     1    517     515   2.00   830    819  11.0  UA     1545
##  2  2013     1     1    533     529   4.00   850    830  20.0  UA     1714
##  3  2013     1     1    542     540   2.00   923    850  33.0  AA     1141
##  4  2013     1     1    544     545  -1.00  1004   1022 -18.0  B6      725
##  5  2013     1     1    554     600  -6.00   812    837 -25.0  DL      461
##  6  2013     1     1    554     558  -4.00   740    728  12.0  UA     1696
##  7  2013     1     1    555     600  -5.00   913    854  19.0  B6      507
##  8  2013     1     1    557     600  -3.00   709    723 -14.0  EV     5708
##  9  2013     1     1    557     600  -3.00   838    846 - 8.00 B6       79
## 10  2013     1     1    558     600  -2.00   753    745   8.00 AA      301
## # ... with more rows, and 9 more variables: tailnum &lt;chr&gt;, origin &lt;chr&gt;,
## #   dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;,
## #   time_hour &lt;dbl&gt;, speed &lt;dbl&gt;
</code></pre>

<h2 id="laziness">Laziness</h2>

<p>When working with databases, dplyr tries to be as lazy as possible:</p>

<ul>
<li><p>It never pulls data into R unless you explicitly ask for it.</p></li>

<li><p>It delays doing any work until the last possible moment: it collects
together everything you want to do and then sends it to the database
in one step.</p></li>
</ul>

<p>For example, take the following
code:</p>

<pre><code class="language-r">c1 &lt;- filter(flights, day == 17, month == 5, carrier %in% c('UA', 'WN', 'AA', 'DL'))
c2 &lt;- select(c1, year, month, day, carrier, dep_delay, air_time, distance)
c3 &lt;- arrange(c2, year, month, day, carrier)
c4 &lt;- mutate(c3, air_time_hours = air_time / 60)
</code></pre>

<p>This sequence of operations never actually touches the database. It’s
not until you ask for the data (e.g. by printing <code>c4</code>) that dplyr
requests the results from the database.</p>

<pre><code class="language-r">c4
</code></pre>

<pre><code>## # Source: lazy query [?? x 8]
## # Database: spark_connection
## # Ordered by: year, month, day, carrier
##     year month   day carrier dep_delay air_time distance air_time_hours
##    &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;          &lt;dbl&gt;
##  1  2013     5    17 AA          -2.00      294     2248           4.90
##  2  2013     5    17 AA          -1.00      146     1096           2.43
##  3  2013     5    17 AA          -2.00      185     1372           3.08
##  4  2013     5    17 AA          -9.00      186     1389           3.10
##  5  2013     5    17 AA           2.00      147     1096           2.45
##  6  2013     5    17 AA          -4.00      114      733           1.90
##  7  2013     5    17 AA          -7.00      117      733           1.95
##  8  2013     5    17 AA          -7.00      142     1089           2.37
##  9  2013     5    17 AA          -6.00      148     1089           2.47
## 10  2013     5    17 AA          -7.00      137      944           2.28
## # ... with more rows
</code></pre>

<h2 id="piping">Piping</h2>

<p>You can use
<a href="https://cran.r-project.org/web/packages/magrittr/vignettes/magrittr.html">magrittr</a>
pipes to write cleaner syntax. Using the same example from above, you
can write a much cleaner version like this:</p>

<pre><code class="language-r">c4 &lt;- flights %&gt;%
  filter(month == 5, day == 17, carrier %in% c('UA', 'WN', 'AA', 'DL')) %&gt;%
  select(carrier, dep_delay, air_time, distance) %&gt;%
  arrange(carrier) %&gt;%
  mutate(air_time_hours = air_time / 60)
</code></pre>

<h2 id="grouping">Grouping</h2>

<p>The <code>group_by</code> function corresponds to the <code>GROUP BY</code> statement in SQL.</p>

<pre><code class="language-r">c4 %&gt;%
  group_by(carrier) %&gt;%
  summarize(count = n(), mean_dep_delay = mean(dep_delay))
</code></pre>

<pre><code>## Warning: Missing values are always removed in SQL.
## Use `AVG(x, na.rm = TRUE)` to silence this warning

## # Source: lazy query [?? x 3]
## # Database: spark_connection
##   carrier count mean_dep_delay
##   &lt;chr&gt;   &lt;dbl&gt;          &lt;dbl&gt;
## 1 AA       94.0           1.47
## 2 DL      136             6.24
## 3 UA      172             9.63
## 4 WN       34.0           7.97
</code></pre>

<h2 id="collecting-to-r">Collecting to R</h2>

<p>You can copy data from Spark into R’s memory by using <code>collect()</code>.</p>

<pre><code class="language-r">carrierhours &lt;- collect(c4)
</code></pre>

<p><code>collect()</code> executes the Spark query and returns the results to R for
further analysis and visualization.</p>

<pre><code class="language-r"># Test the significance of pairwise differences and plot the results
with(carrierhours, pairwise.t.test(air_time, carrier))
</code></pre>

<pre><code>## 
##  Pairwise comparisons using t tests with pooled SD 
## 
## data:  air_time and carrier 
## 
##    AA      DL      UA     
## DL 0.25057 -       -      
## UA 0.07957 0.00044 -      
## WN 0.07957 0.23488 0.00041
## 
## P value adjustment method: holm
</code></pre>

<pre><code class="language-r">ggplot(carrierhours, aes(carrier, air_time_hours)) + geom_boxplot()
</code></pre>

<p><img src="guides-dplyr_files/figure-gfm/unnamed-chunk-12-1.png" alt="" /><!-- --></p>

<h2 id="sql-translation">SQL Translation</h2>

<p>It’s relatively straightforward to translate R code to SQL (or indeed to
any programming language) when doing simple mathematical operations of
the form you normally use when filtering, mutating and summarizing.
dplyr knows how to convert the following R functions to Spark SQL:</p>

<pre><code class="language-r"># Basic math operators
+, -, *, /, %%, ^
  
# Math functions
abs, acos, asin, asinh, atan, atan2, ceiling, cos, cosh, exp, floor, log, log10, round, sign, sin, sinh, sqrt, tan, tanh

# Logical comparisons
&lt;, &lt;=, !=, &gt;=, &gt;, ==, %in%

# Boolean operations
&amp;, &amp;&amp;, |, ||, !

# Character functions
paste, tolower, toupper, nchar

# Casting
as.double, as.integer, as.logical, as.character, as.date

# Basic aggregations
mean, sum, min, max, sd, var, cor, cov, n
</code></pre>

<h2 id="window-functions">Window Functions</h2>

<p>dplyr supports Spark SQL window functions. Window functions are used in
conjunction with mutate and filter to solve a wide range of problems.
You can compare the dplyr syntax to the query it has generated by using
<code>dbplyr::sql_render()</code>.</p>

<pre><code class="language-r"># Find the most and least delayed flight each day
bestworst &lt;- flights %&gt;%
  group_by(year, month, day) %&gt;%
  select(dep_delay) %&gt;% 
  filter(dep_delay == min(dep_delay) || dep_delay == max(dep_delay))
dbplyr::sql_render(bestworst)
## Warning: Missing values are always removed in SQL.
## Use `min(x, na.rm = TRUE)` to silence this warning
## Warning: Missing values are always removed in SQL.
## Use `max(x, na.rm = TRUE)` to silence this warning
## &lt;SQL&gt; SELECT `year`, `month`, `day`, `dep_delay`
## FROM (SELECT `year`, `month`, `day`, `dep_delay`, min(`dep_delay`) OVER (PARTITION BY `year`, `month`, `day`) AS `zzz3`, max(`dep_delay`) OVER (PARTITION BY `year`, `month`, `day`) AS `zzz4`
## FROM (SELECT `year`, `month`, `day`, `dep_delay`
## FROM `flights`) `coaxmtqqbj`) `efznnpuovy`
## WHERE (`dep_delay` = `zzz3` OR `dep_delay` = `zzz4`)
bestworst
## Warning: Missing values are always removed in SQL.
## Use `min(x, na.rm = TRUE)` to silence this warning

## Warning: Missing values are always removed in SQL.
## Use `max(x, na.rm = TRUE)` to silence this warning
## # Source: lazy query [?? x 4]
## # Database: spark_connection
## # Groups: year, month, day
##     year month   day dep_delay
##    &lt;int&gt; &lt;int&gt; &lt;int&gt;     &lt;dbl&gt;
##  1  2013     1     1     853  
##  2  2013     1     1   -  15.0
##  3  2013     1     1   -  15.0
##  4  2013     1     9    1301  
##  5  2013     1     9   -  17.0
##  6  2013     1    24   -  15.0
##  7  2013     1    24     329  
##  8  2013     1    29   -  27.0
##  9  2013     1    29     235  
## 10  2013     2     1   -  15.0
## # ... with more rows
</code></pre>

<pre><code class="language-r"># Rank each flight within a daily
ranked &lt;- flights %&gt;%
  group_by(year, month, day) %&gt;%
  select(dep_delay) %&gt;% 
  mutate(rank = rank(desc(dep_delay)))
dbplyr::sql_render(ranked)
</code></pre>

<pre><code>## &lt;SQL&gt; SELECT `year`, `month`, `day`, `dep_delay`, rank() OVER (PARTITION BY `year`, `month`, `day` ORDER BY `dep_delay` DESC) AS `rank`
## FROM (SELECT `year`, `month`, `day`, `dep_delay`
## FROM `flights`) `mauqwkxuam`
</code></pre>

<pre><code class="language-r">ranked
</code></pre>

<pre><code>## # Source: lazy query [?? x 5]
## # Database: spark_connection
## # Groups: year, month, day
##     year month   day dep_delay  rank
##    &lt;int&gt; &lt;int&gt; &lt;int&gt;     &lt;dbl&gt; &lt;int&gt;
##  1  2013     1     1       853     1
##  2  2013     1     1       379     2
##  3  2013     1     1       290     3
##  4  2013     1     1       285     4
##  5  2013     1     1       260     5
##  6  2013     1     1       255     6
##  7  2013     1     1       216     7
##  8  2013     1     1       192     8
##  9  2013     1     1       157     9
## 10  2013     1     1       155    10
## # ... with more rows
</code></pre>

<h2 id="peforming-joins">Peforming Joins</h2>

<p>It’s rare that a data analysis involves only a single table of data. In
practice, you’ll normally have many tables that contribute to an
analysis, and you need flexible tools to combine them. In dplyr, there
are three families of verbs that work with two tables at a time:</p>

<ul>
<li><p>Mutating joins, which add new variables to one table from matching
rows in another.</p></li>

<li><p>Filtering joins, which filter observations from one table based on
whether or not they match an observation in the other table.</p></li>

<li><p>Set operations, which combine the observations in the data sets as
if they were set elements.</p></li>
</ul>

<p>All two-table verbs work similarly. The first two arguments are <code>x</code> and
<code>y</code>, and provide the tables to combine. The output is always a new table
with the same type as <code>x</code>.</p>

<p>The following statements are equivalent:</p>

<pre><code class="language-r">flights %&gt;% left_join(airlines)
</code></pre>

<pre><code>## Joining, by = &quot;carrier&quot;

## # Source: lazy query [?? x 20]
## # Database: spark_connection
##     year month   day dep_t~ sched_~ dep_d~ arr_~ sched~ arr_d~ carr~ flig~
##    &lt;int&gt; &lt;int&gt; &lt;int&gt;  &lt;int&gt;   &lt;int&gt;  &lt;dbl&gt; &lt;int&gt;  &lt;int&gt;  &lt;dbl&gt; &lt;chr&gt; &lt;int&gt;
##  1  2013     1     1    517     515   2.00   830    819  11.0  UA     1545
##  2  2013     1     1    533     529   4.00   850    830  20.0  UA     1714
##  3  2013     1     1    542     540   2.00   923    850  33.0  AA     1141
##  4  2013     1     1    544     545  -1.00  1004   1022 -18.0  B6      725
##  5  2013     1     1    554     600  -6.00   812    837 -25.0  DL      461
##  6  2013     1     1    554     558  -4.00   740    728  12.0  UA     1696
##  7  2013     1     1    555     600  -5.00   913    854  19.0  B6      507
##  8  2013     1     1    557     600  -3.00   709    723 -14.0  EV     5708
##  9  2013     1     1    557     600  -3.00   838    846 - 8.00 B6       79
## 10  2013     1     1    558     600  -2.00   753    745   8.00 AA      301
## # ... with more rows, and 9 more variables: tailnum &lt;chr&gt;, origin &lt;chr&gt;,
## #   dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;,
## #   time_hour &lt;dbl&gt;, name &lt;chr&gt;
</code></pre>

<pre><code class="language-r">flights %&gt;% left_join(airlines, by = &quot;carrier&quot;)
</code></pre>

<pre><code>## # Source: lazy query [?? x 20]
## # Database: spark_connection
##     year month   day dep_t~ sched_~ dep_d~ arr_~ sched~ arr_d~ carr~ flig~
##    &lt;int&gt; &lt;int&gt; &lt;int&gt;  &lt;int&gt;   &lt;int&gt;  &lt;dbl&gt; &lt;int&gt;  &lt;int&gt;  &lt;dbl&gt; &lt;chr&gt; &lt;int&gt;
##  1  2013     1     1    517     515   2.00   830    819  11.0  UA     1545
##  2  2013     1     1    533     529   4.00   850    830  20.0  UA     1714
##  3  2013     1     1    542     540   2.00   923    850  33.0  AA     1141
##  4  2013     1     1    544     545  -1.00  1004   1022 -18.0  B6      725
##  5  2013     1     1    554     600  -6.00   812    837 -25.0  DL      461
##  6  2013     1     1    554     558  -4.00   740    728  12.0  UA     1696
##  7  2013     1     1    555     600  -5.00   913    854  19.0  B6      507
##  8  2013     1     1    557     600  -3.00   709    723 -14.0  EV     5708
##  9  2013     1     1    557     600  -3.00   838    846 - 8.00 B6       79
## 10  2013     1     1    558     600  -2.00   753    745   8.00 AA      301
## # ... with more rows, and 9 more variables: tailnum &lt;chr&gt;, origin &lt;chr&gt;,
## #   dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;,
## #   time_hour &lt;dbl&gt;, name &lt;chr&gt;
</code></pre>

<pre><code class="language-r">flights %&gt;% left_join(airlines, by = c(&quot;carrier&quot;, &quot;carrier&quot;))
</code></pre>

<pre><code>## # Source: lazy query [?? x 20]
## # Database: spark_connection
##     year month   day dep_t~ sched_~ dep_d~ arr_~ sched~ arr_d~ carr~ flig~
##    &lt;int&gt; &lt;int&gt; &lt;int&gt;  &lt;int&gt;   &lt;int&gt;  &lt;dbl&gt; &lt;int&gt;  &lt;int&gt;  &lt;dbl&gt; &lt;chr&gt; &lt;int&gt;
##  1  2013     1     1    517     515   2.00   830    819  11.0  UA     1545
##  2  2013     1     1    533     529   4.00   850    830  20.0  UA     1714
##  3  2013     1     1    542     540   2.00   923    850  33.0  AA     1141
##  4  2013     1     1    544     545  -1.00  1004   1022 -18.0  B6      725
##  5  2013     1     1    554     600  -6.00   812    837 -25.0  DL      461
##  6  2013     1     1    554     558  -4.00   740    728  12.0  UA     1696
##  7  2013     1     1    555     600  -5.00   913    854  19.0  B6      507
##  8  2013     1     1    557     600  -3.00   709    723 -14.0  EV     5708
##  9  2013     1     1    557     600  -3.00   838    846 - 8.00 B6       79
## 10  2013     1     1    558     600  -2.00   753    745   8.00 AA      301
## # ... with more rows, and 9 more variables: tailnum &lt;chr&gt;, origin &lt;chr&gt;,
## #   dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;,
## #   time_hour &lt;dbl&gt;, name &lt;chr&gt;
</code></pre>

<h2 id="sampling">Sampling</h2>

<p>You can use <code>sample_n()</code> and <code>sample_frac()</code> to take a random sample of
rows: use <code>sample_n()</code> for a fixed number and <code>sample_frac()</code> for a
fixed fraction.</p>

<pre><code class="language-r">sample_n(flights, 10)
</code></pre>

<pre><code>## # Source: lazy query [?? x 19]
## # Database: spark_connection
##     year month   day dep_t~ sched_~ dep_d~ arr_~ sched~ arr_d~ carr~ flig~
##    &lt;int&gt; &lt;int&gt; &lt;int&gt;  &lt;int&gt;   &lt;int&gt;  &lt;dbl&gt; &lt;int&gt;  &lt;int&gt;  &lt;dbl&gt; &lt;chr&gt; &lt;int&gt;
##  1  2013     1     1    517     515   2.00   830    819  11.0  UA     1545
##  2  2013     1     1    533     529   4.00   850    830  20.0  UA     1714
##  3  2013     1     1    542     540   2.00   923    850  33.0  AA     1141
##  4  2013     1     1    544     545  -1.00  1004   1022 -18.0  B6      725
##  5  2013     1     1    554     600  -6.00   812    837 -25.0  DL      461
##  6  2013     1     1    554     558  -4.00   740    728  12.0  UA     1696
##  7  2013     1     1    555     600  -5.00   913    854  19.0  B6      507
##  8  2013     1     1    557     600  -3.00   709    723 -14.0  EV     5708
##  9  2013     1     1    557     600  -3.00   838    846 - 8.00 B6       79
## 10  2013     1     1    558     600  -2.00   753    745   8.00 AA      301
## # ... with more rows, and 8 more variables: tailnum &lt;chr&gt;, origin &lt;chr&gt;,
## #   dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;,
## #   time_hour &lt;dbl&gt;
</code></pre>

<pre><code class="language-r">sample_frac(flights, 0.01)
</code></pre>

<pre><code>## # Source: lazy query [?? x 19]
## # Database: spark_connection
##     year month   day dep_t~ sched_~ dep_d~ arr_~ sched~ arr_d~ carr~ flig~
##    &lt;int&gt; &lt;int&gt; &lt;int&gt;  &lt;int&gt;   &lt;int&gt;  &lt;dbl&gt; &lt;int&gt;  &lt;int&gt;  &lt;dbl&gt; &lt;chr&gt; &lt;int&gt;
##  1  2013     1     1    655     655   0     1021   1030 - 9.00 DL     1415
##  2  2013     1     1    656     700 - 4.00   854    850   4.00 AA      305
##  3  2013     1     1   1044    1045 - 1.00  1231   1212  19.0  EV     4322
##  4  2013     1     1   1056    1059 - 3.00  1203   1209 - 6.00 EV     4479
##  5  2013     1     1   1317    1325 - 8.00  1454   1505 -11.0  MQ     4475
##  6  2013     1     1   1708    1700   8.00  2037   2005  32.0  WN     1066
##  7  2013     1     1   1825    1829 - 4.00  2056   2053   3.00 9E     3286
##  8  2013     1     1   1843    1845 - 2.00  1955   2024 -29.0  DL      904
##  9  2013     1     1   2108    2057  11.0     25     39 -14.0  UA     1517
## 10  2013     1     2    557     605 - 8.00   832    823   9.00 DL      544
## # ... with more rows, and 8 more variables: tailnum &lt;chr&gt;, origin &lt;chr&gt;,
## #   dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;,
## #   time_hour &lt;dbl&gt;
</code></pre>

<h2 id="writing-data">Writing Data</h2>

<p>It is often useful to save the results of your analysis or the tables
that you have generated on your Spark cluster into persistent storage.
The best option in many scenarios is to write the table out to a
<a href="https://parquet.apache.org/">Parquet</a> file using the
<a href="reference/sparklyr/spark_write_parquet.html">spark_write_parquet</a>
function. For example:</p>

<pre><code class="language-r">spark_write_parquet(tbl, &quot;hdfs://hdfs.company.org:9000/hdfs-path/data&quot;)
</code></pre>

<p>This will write the Spark DataFrame referenced by the tbl R variable to
the given HDFS path. You can use the
<a href="reference/sparklyr/spark_read_parquet.html">spark_read_parquet</a>
function to read the same table back into a subsequent Spark
session:</p>

<pre><code class="language-r">tbl &lt;- spark_read_parquet(sc, &quot;data&quot;, &quot;hdfs://hdfs.company.org:9000/hdfs-path/data&quot;)
</code></pre>

<p>You can also write data as CSV or JSON using the
<a href="reference/sparklyr/spark_write_csv.html">spark_write_csv</a> and
<a href="reference/sparklyr/spark_write_json.html">spark_write_json</a>
functions.</p>

<h2 id="hive-functions">Hive Functions</h2>

<p>Many of Hive’s built-in functions (UDF) and built-in aggregate functions
(UDAF) can be called inside dplyr’s mutate and summarize. The <a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF">Languange
Reference
UDF</a>
page provides the list of available functions.</p>

<p>The following example uses the <strong>datediff</strong> and <strong>current_date</strong> Hive
UDFs to figure the difference between the flight_date and the current
system date:</p>

<pre><code class="language-r">flights %&gt;% 
  mutate(flight_date = paste(year,month,day,sep=&quot;-&quot;),
         days_since = datediff(current_date(), flight_date)) %&gt;%
  group_by(flight_date,days_since) %&gt;%
  tally() %&gt;%
  arrange(-days_since)
</code></pre>

<pre><code>## # Source: lazy query [?? x 3]
## # Database: spark_connection
## # Groups: flight_date
## # Ordered by: -days_since
##    flight_date days_since     n
##    &lt;chr&gt;            &lt;int&gt; &lt;dbl&gt;
##  1 2013-1-1          1844   842
##  2 2013-1-2          1843   943
##  3 2013-1-3          1842   914
##  4 2013-1-4          1841   915
##  5 2013-1-5          1840   720
##  6 2013-1-6          1839   832
##  7 2013-1-7          1838   933
##  8 2013-1-8          1837   899
##  9 2013-1-9          1836   902
## 10 2013-1-10         1835   932
## # ... with more rows
</code></pre>

        
      </div>
      </div>
      </div>
      
      
<footer>



<script type="text/javascript">
(function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){
(w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);
e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);
})(window,document,'script','//s.swiftypecdn.com/install/v2/st.js','_st');

_st('install','ubj6WcBvA61Exph85z7Q','2.0.0');
</script>

</footer>
      
    </div>
</div>

</body>
</html>

