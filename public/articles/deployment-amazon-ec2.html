<!DOCTYPE html>
<html>
<head>
  <script>
    theBaseUrl = location.origin + "/";
  </script>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width,user-scalable=no,initial-scale=1,maximum-scale=1">
  <title>Spark Standalone Deployment in AWS</title>
  <meta name="generator" content="Hugo 0.26" />

  
  <meta name="description" content="Documentation for the Spark for R interface">
  
  <link rel="canonical" href="/articles/deployment-amazon-ec2.html">
  
  <meta name="author" content="Javier Luraschii">
  

  <meta property="og:url" content="/articles/deployment-amazon-ec2.html">
  <meta property="og:title" content="sparklyr">
  <meta name="apple-mobile-web-app-title" content="sparklyr">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

  <style>
    @font-face {
      font-family: 'Icon';
      src: url('fonts/icon.eot?52m981');
      src: url('fonts/icon.eot?#iefix52m981')
      format('embedded-opentype'),
      url('fonts/icon.woff?52m981')
      format('woff'),
      url('fonts/icon.ttf?52m981')
      format('truetype'),
      url('fonts/icon.svg?52m981#icon')
      format('svg');
      font-weight: normal;
      font-style: normal;
    }
  </style>


  <link rel="stylesheet" href="/css/style.css">
  <link rel="stylesheet" href="/css/site-styles.css">

  <script src="/js/vendor.js"></script>

  <script src="/js/app.js"></script>
  
  <link rel="shortcut icon" href="/images/favicon.png">

  
</head>
<body>


<div class="single-page">
  <nav data-gumshoe-header aria-label="Header" id="header" class="top-menu">
  <div class="left">
     <a href = "/" data-parenturl="" class="top-menu-item site-title">sparklyr</a>
     <span class="logo-from">from</span>
     <a href="/">
      <div id="logo" class="logo"></div>
    </a>
  </div>

  
  

  <div class="right">
    <div class="top-menu-items" id="top-menu-items">
      
        <a href="/articles/guides-dplyr" data-parenturl="/articles/guides-dplyr" class="top-menu-item">dplyr</a>
      
    </div>

    <a href="https://github.com/rstudio/sparklyr" class="github-logo">
      <i class="fa fa-lg fa-github" aria-hidden="true"></i>
    </a>

    <div class="search-button">
      <i class="fa fa-lg fa-search"></i>
    </div>
    
  </div>
</nav>

<nav aria-label="Header" id="mobile-header">
  <a href = "/">sparklyr</a>
  <div class="right">
    <a href="https://github.com/rstudio/sparklyr" class="github-logo">
      <i class="fa fa-lg fa-github" aria-hidden="true"></i>
    </a>
    <div class="hamburger">
      <i class="fa fa-lg fa-bars" aria-hidden="true"></i>
    </div>
  </div>

</nav>

<div id="mobile-menu-container">
<ul id="mobile-menu">
  
    <li>
      <a href="/articles/guides-dplyr">dplyr</a>
       
    </li>
    <ul>
    
    </ul>
  
</ul>
</div>

<div id="search-bar" class="search-bar">
  <p class="search-bar__icon"><i class="fa fa-lg fa-search"></i> </p>
  <div class="search-bar__input">
      <input type="text" name="search" class="st-default-search-input">
  </div>
  <div class="search-bar__exit">
    <i class="fa fa-lg fa-times"></i>
  </div>

  <div class="inline-search-results">
    <ul>

    </ul>
  </div>
</div>



</div>

<div class="page documentation">
    <div class="side-menu" id="side-menu">
    
    
    
    </div>
    <div class="content">

      <h1 class="content-header">Spark Standalone Deployment in AWS </h1>

      <div class="markdowned">
        <div id="overview" class="section level2">
<h2>Overview</h2>
<p>The plan is to launch 4 identical EC2 server instances. One server will be the Master node and the other 3 the worker nodes. In one of the worker nodes, we will install RStudio server.</p>
<p>What makes a server the Master node is only the fact that it is running the <strong>master</strong> service, while the other machines are running the <strong>slave</strong> service and are pointed to that first master. This simple setup, allows us to install the same Spark components on all 4 servers and then just add RStudio to one of them.</p>
<p>The topology will look something like this:</p>
<p>
<img src="images/deployment/amazon-ec2/spark-sa-setup.png" width="600px" align="center"></p>
</div>
<div id="aws-ec-instances" class="section level2">
<h2>AWS EC Instances</h2>
<p>Here are the details of the EC2 instance, just deploy one at this point:</p>
<ul>
<li>
<strong>Type:</strong> t2.medium</li>
<li>
<strong>OS:</strong> Ubuntu 16.04 LTS</li>
<li>
<strong>Disk space:</strong> At least 20GB</li>
<li>
<strong>Security group:</strong> Open the following ports: 8080 (Spark UI), 4040 (Spark Worker UI), 8088 (sparklyr UI) and 8787 (RStudio). Also open <em>All TCP</em> ports for the machines inside the security group.</li>
</ul>
</div>
<div id="spark" class="section level2">
<h2>Spark</h2>
<p>Perform the steps in this section on all of the servers that will be part of the cluster.</p>
<div id="install-java-8" class="section level3">
<h3>Install Java 8</h3>
<ul>
<li>
<p>We will add the Java 8 repository, install it and set it as default</p>
<pre><code>sudo apt-add-repository ppa:webupd8team/java
sudo apt-get update
sudo apt-get install oracle-java8-installer
sudo apt-get install oracle-java8-set-default
sudo apt-get update</code></pre>
</li>
</ul>
</div>
<div id="download-spark" class="section level3">
<h3>Download Spark</h3>
<ul>
<li>
<p>Download and unpack a pre-compiled version of Spark. Here’s is the link to the <a href="http://spark.apache.org/downloads.html">official Spark download page</a></p>
<pre><code>wget http://d3kbcqa49mib13.cloudfront.net/spark-2.1.0-bin-hadoop2.7.tgz
tar -xvzf spark-2.1.0-bin-hadoop2.7.tgz
cd spark-2.1.0-bin-hadoop2.7</code></pre>
</li>
</ul>
</div>
<div id="create-and-launch-ami" class="section level3">
<h3>Create and launch AMI</h3>
<ul>
<li><p>We will create an image of the server. In Amazon, these are called AMIs, for information please see the <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AMIs.html">User Guide</a>.</p></li>
<li><p>Launch 3 instances of the AMI</p></li>
</ul>
</div>
</div>
<div id="rstudio-server" class="section level2">
<h2>RStudio Server</h2>
<p>Select one of the nodes to execute this section. Please check the <a href="https://www.rstudio.com/products/rstudio/download-server/">RStudio download page</a> for the latest version</p>
<div id="install-r" class="section level3">
<h3>Install R</h3>
<ul>
<li>
<p>In order to get the latest R core, we will need to update the source list in Ubuntu.</p>
<pre><code>sudo sh -c 'echo "deb http://cran.rstudio.com/bin/linux/ubuntu xenial/" &gt;&gt; /etc/apt/sources.list'
gpg --keyserver keyserver.ubuntu.com --recv-key E084DAB9
gpg -a --export E084DAB9 | sudo apt-key add -
sudo apt-get update</code></pre>
</li>
<li>
<p>Now we can install R</p>
<pre><code>sudo apt-get install r-base
sudo apt-get install gdebi-core</code></pre>
</li>
</ul>
</div>
<div id="install-rstudio" class="section level3">
<h3>Install RStudio</h3>
<ul>
<li>
<p>We will download and install 1.044 of RStudio Server. To find the latest version, please visit the <a href="https://www.rstudio.com/products/rstudio/download3/">RStudio website</a>. In order to get the enhanced integration with Spark, RStudio version 1.044 or later will be needed.</p>
<pre><code>wget https://download2.rstudio.org/rstudio-server-1.0.153-amd64.deb
sudo gdebi rstudio-server-1.0.153-amd64.deb</code></pre>
</li>
</ul>
</div>
<div id="install-dependencies" class="section level3">
<h3>Install dependencies</h3>
<ul>
<li>
<p>Run the following commands</p>
<pre><code>sudo apt-get -y install libcurl4-gnutls-dev
sudo apt-get -y install libssl-dev
sudo apt-get -y install libxml2-dev</code></pre>
</li>
</ul>
</div>
<div id="add-default-user" class="section level3">
<h3>Add default user</h3>
<ul>
<li>
<p>Run the following command to add a default user</p>
<pre><code>sudo adduser rstudio-user</code></pre>
</li>
</ul>
</div>
<div id="start-the-master-node" class="section level3">
<h3>Start the Master node</h3>
<ul>
<li><p>Select one of the servers to become your Master node</p></li>
<li>
<p>Run the command that starts the master service</p>
<pre><code>sudo spark-2.1.0-bin-hadoop2.7/sbin/start-master.sh</code></pre>
</li>
<li><p>Close the terminal connection (optional)</p></li>
</ul>
</div>
<div id="start-worker-nodes" class="section level3">
<h3>Start Worker nodes</h3>
<ul>
<li>
<p>Start the slave service. <strong>Important</strong>: Use dots not dashes as separators for the Spark Master node’s address</p>
<pre><code>sudo spark-2.1.0-bin-hadoop2.7/sbin/start-slave.sh spark://[Master node's IP address]:7077</code></pre>
sudo spark-2.1.0-bin-hadoop2.7/sbin/start-slave.sh spark://ip-172-30-1-94.us-west-2.compute.internal:7077</li>
<li><p>Close the terminal connection (optional)</p></li>
</ul>
</div>
<div id="pre-load-pacakges" class="section level3">
<h3>Pre-load pacakges</h3>
<ul>
<li><p>Log into RStudio (port 8787)</p></li>
<li>
<p>Use ‘rstudio-user’</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">install.packages</span>(<span class="st">"sparklyr"</span>)</code></pre></div>
</li>
</ul>
</div>
<div id="connect-to-the-spark-master" class="section level3">
<h3>Connect to the Spark Master</h3>
<ul>
<li><p>Navigate to the Spark Master’s UI, typically on port 8080 <img src="images/deployment/amazon-ec2/spark-master.png" class="screenshot" width="639"></p></li>
<li><p>Note the <strong>Spark Master URL</strong></p></li>
<li><p>Logon to RStudio</p></li>
<li><p>Run the following code</p></li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">
<span class="kw">library</span>(sparklyr)

conf &lt;-<span class="st"> </span><span class="kw">spark_config</span>()
conf<span class="op">$</span>spark.executor.memory &lt;-<span class="st"> "2GB"</span>
conf<span class="op">$</span>spark.memory.fraction &lt;-<span class="st"> </span><span class="fl">0.9</span>

sc &lt;-<span class="st"> </span><span class="kw">spark_connect</span>(<span class="dt">master=</span><span class="st">"[Spark Master URL]"</span>, 
              <span class="dt">version =</span> <span class="st">"2.1.0"</span>,
              <span class="dt">config =</span> conf,
              <span class="dt">spark_home =</span> <span class="st">"/home/ubuntu/spark-2.1.0-bin-hadoop2.7/"</span>)</code></pre></div>
</div>
</div>

      </div>
      
      
<footer>



</footer>
      
    </div>
</div>

</body>
</html>

