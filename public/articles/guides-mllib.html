<!DOCTYPE html>
<html>
<head>
  <script>
    theBaseUrl = location.origin + "/";
  </script>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width,user-scalable=no,initial-scale=1,maximum-scale=1">
  <title>Spark Machine Learning Library (MLlib)</title>
  <meta name="generator" content="Hugo 0.26" />

  
  <meta name="description" content="Documentation for the Spark for R interface">
  
  <link rel="canonical" href="/articles/guides-mllib.html">
  
  <meta name="author" content="Javier Luraschii">
  

  <meta property="og:url" content="/articles/guides-mllib.html">
  <meta property="og:title" content="sparklyr">
  <meta name="apple-mobile-web-app-title" content="sparklyr">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

  <style>
    @font-face {
      font-family: 'Icon';
      src: url('fonts/icon.eot?52m981');
      src: url('fonts/icon.eot?#iefix52m981')
      format('embedded-opentype'),
      url('fonts/icon.woff?52m981')
      format('woff'),
      url('fonts/icon.ttf?52m981')
      format('truetype'),
      url('fonts/icon.svg?52m981#icon')
      format('svg');
      font-weight: normal;
      font-style: normal;
    }
  </style>


  <link rel="stylesheet" href="/css/style.css">
  <link rel="stylesheet" href="/css/site-styles.css">

  <script src="/js/vendor.js"></script>

  <script src="/js/app.js"></script>
  
  <link rel="shortcut icon" href="/images/favicon.png">

  
</head>
<body>


<div class="single-page">
  <nav data-gumshoe-header aria-label="Header" id="header" class="top-menu">
  <div class="left">
     <a href = "/" data-parenturl="" class="top-menu-item site-title">sparklyr</a>
     <span class="logo-from">from</span>
     <a href="/">
      <div id="logo" class="logo"></div>
    </a>
  </div>

  
  

  <div class="right">
    <div class="top-menu-items" id="top-menu-items">
      
        <a href="/articles/guides-dplyr" data-parenturl="/articles/guides-dplyr" class="top-menu-item">dplyr</a>
      
    </div>

    <a href="https://github.com/rstudio/sparklyr" class="github-logo">
      <i class="fa fa-lg fa-github" aria-hidden="true"></i>
    </a>

    <div class="search-button">
      <i class="fa fa-lg fa-search"></i>
    </div>
    
  </div>
</nav>

<nav aria-label="Header" id="mobile-header">
  <a href = "/">sparklyr</a>
  <div class="right">
    <a href="https://github.com/rstudio/sparklyr" class="github-logo">
      <i class="fa fa-lg fa-github" aria-hidden="true"></i>
    </a>
    <div class="hamburger">
      <i class="fa fa-lg fa-bars" aria-hidden="true"></i>
    </div>
  </div>

</nav>

<div id="mobile-menu-container">
<ul id="mobile-menu">
  
    <li>
      <a href="/articles/guides-dplyr">dplyr</a>
       
    </li>
    <ul>
    
    </ul>
  
</ul>
</div>

<div id="search-bar" class="search-bar">
  <p class="search-bar__icon"><i class="fa fa-lg fa-search"></i> </p>
  <div class="search-bar__input">
      <input type="text" name="search" class="st-default-search-input">
  </div>
  <div class="search-bar__exit">
    <i class="fa fa-lg fa-times"></i>
  </div>

  <div class="inline-search-results">
    <ul>

    </ul>
  </div>
</div>



</div>

<div class="page documentation">
    <div class="side-menu" id="side-menu">
    
    
    
    </div>
    <div class="content">

      <h1 class="content-header">Spark Machine Learning Library (MLlib) </h1>

      <div class="markdowned">
        <div id="overview" class="section level2">
<h2>Overview</h2>
<p><strong>sparklyr</strong> provides bindings to Spark’s distributed <a href="https://spark.apache.org/docs/latest/mllib-guide.html">machine learning</a> library. In particular, sparklyr allows you to access the machine learning routines provided by the <a href="https://spark.apache.org/docs/latest/ml-guide.html">spark.ml</a> package. Together with sparklyr’s <a href="dplyr.html">dplyr</a> interface, you can easily create and tune machine learning workflows on Spark, orchestrated entirely within R.</p>
<p>sparklyr provides three families of functions that you can use with Spark machine learning:</p>
<ul>
<li>Machine learning algorithms for analyzing data (<code>ml_*</code>)</li>
<li>Feature transformers for manipulating individual features (<code>ft_*</code>)</li>
<li>Functions for manipulating Spark DataFrames (<code>sdf_*</code>)</li>
</ul>
<p>An analytic workflow with sparklyr might be composed of the following stages. For an example see <a href="#example-workflow">Example Workflow</a>.</p>
<ol style="list-style-type: decimal">
<li>Perform SQL queries through the sparklyr <a href="dplyr.html">dplyr</a> interface,</li>
<li>Use the <code>sdf_*</code> and <code>ft_*</code> family of functions to generate new columns, or partition your data set,</li>
<li>Choose an appropriate machine learning algorithm from the <code>ml_*</code> family of functions to model your data,</li>
<li>Inspect the quality of your model fit, and use it to make predictions with new data.</li>
<li>Collect the results for visualization and further analysis in R</li>
</ol>
</div>
<div id="algorithms" class="section level2">
<h2>Algorithms</h2>
<p>Spark’s machine learning library can be accessed from sparklyr through the <code>ml_*</code> set of functions:</p>
<table>
<thead><tr class="header">
<th>Function</th>
<th>Description</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><a href="reference/sparklyr/latest/ml_kmeans.html"><code>ml_kmeans</code></a></td>
<td>K-Means Clustering</td>
</tr>
<tr class="even">
<td><a href="reference/sparklyr/latest/ml_linear_regression.html"><code>ml_linear_regression</code></a></td>
<td>Linear Regression</td>
</tr>
<tr class="odd">
<td><a href="reference/sparklyr/latest/ml_logistic_regression.html"><code>ml_logistic_regression</code></a></td>
<td>Logistic Regression</td>
</tr>
<tr class="even">
<td><a href="reference/sparklyr/latest/ml_survival_regression.html"><code>ml_survival_regression</code></a></td>
<td>Survival Regression</td>
</tr>
<tr class="odd">
<td><a href="reference/sparklyr/latest/ml_generalized_linear_regression.html"><code>ml_generalized_linear_regression</code></a></td>
<td>Generalized Linear Regression</td>
</tr>
<tr class="even">
<td><a href="reference/sparklyr/latest/ml_decision_tree.html"><code>ml_decision_tree</code></a></td>
<td>Decision Trees</td>
</tr>
<tr class="odd">
<td><a href="reference/sparklyr/latest/ml_random_forest.html"><code>ml_random_forest</code></a></td>
<td>Random Forests</td>
</tr>
<tr class="even">
<td><a href="reference/sparklyr/latest/ml_gradient_boosted_trees.html"><code>ml_gradient_boosted_trees</code></a></td>
<td>Gradient-Boosted Trees</td>
</tr>
<tr class="odd">
<td><a href="reference/sparklyr/latest/ml_pca.html"><code>ml_pca</code></a></td>
<td>Principal Components Analysis</td>
</tr>
<tr class="even">
<td><a href="reference/sparklyr/latest/ml_naive_bayes.html"><code>ml_naive_bayes</code></a></td>
<td>Naive-Bayes</td>
</tr>
<tr class="odd">
<td><a href="reference/sparklyr/latest/ml_multilayer_perceptron.html"><code>ml_multilayer_perceptron</code></a></td>
<td>Multilayer Perceptron</td>
</tr>
<tr class="even">
<td><a href="reference/sparklyr/latest/ml_lda.html"><code>ml_lda</code></a></td>
<td>Latent Dirichlet Allocation</td>
</tr>
<tr class="odd">
<td><a href="reference/sparklyr/latest/ml_lda.html"><code>ml_one_vs_rest</code></a></td>
<td>One vs Rest</td>
</tr>
</tbody>
</table>
<div id="formulas" class="section level3 toc-ignore">
<h3>Formulas</h3>
<p>The <code>ml_*</code> functions take the arguments <code>response</code> and <code>features</code>. But <code>features</code> can also be a formula with main effects (it currently does not accept interaction terms). The intercept term can be omitted by using <code>-1</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Equivalent statements</span>
<span class="kw">ml_linear_regression</span>(z <span class="op">~</span><span class="st"> </span><span class="op">-</span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>x <span class="op">+</span><span class="st"> </span>y)
<span class="kw">ml_linear_regression</span>(<span class="dt">intercept =</span> <span class="ot">FALSE</span>, <span class="dt">response =</span> <span class="st">"z"</span>, <span class="dt">features =</span> <span class="kw">c</span>(<span class="st">"x"</span>, <span class="st">"y"</span>))</code></pre></div>
</div>
<div id="options" class="section level3 toc-ignore">
<h3>Options</h3>
<p>The Spark model output can be modified with the <code>ml_options</code> argument in the <code>ml_*</code> functions. The <code>ml_options</code> is an <em>experts only</em> interface for tweaking the model output. For example, <code>model.transform</code> can be used to mutate the Spark model object before the fit is performed.</p>
</div>
</div>
<div id="transformers" class="section level2">
<h2>Transformers</h2>
<p>A model is often fit not on a dataset as-is, but instead on some transformation of that dataset. Spark provides <a href="http://spark.apache.org/docs/latest/ml-features.html">feature transformers</a>, facilitating many common transformations of data within a Spark DataFrame, and sparklyr exposes these within the <code>ft_*</code> family of functions. These routines generally take one or more input columns, and generate a new output column formed as a transformation of those columns.</p>
<table>
<colgroup>
<col width="38%">
<col width="61%">
</colgroup>
<thead><tr class="header">
<th>Function</th>
<th>Description</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><a href="reference/sparklyr/latest/ft_binarizer.html"><code>ft_binarizer</code></a></td>
<td>Threshold numerical features to binary (0/1) feature</td>
</tr>
<tr class="even">
<td><a href="reference/sparklyr/latest/ft_bucketizer.html"><code>ft_bucketizer</code></a></td>
<td>Bucketizer transforms a column of continuous features to a column of feature buckets</td>
</tr>
<tr class="odd">
<td><a href="reference/sparklyr/latest/ft_discrete_cosine_transform.html"><code>ft_discrete_cosine_transform</code></a></td>
<td>Transforms a length NN real-valued sequence in the time domain into another length NN real-valued sequence in the frequency domain</td>
</tr>
<tr class="even">
<td><a href="reference/sparklyr/latest/ft_elementwise_product.html"><code>ft_elementwise_product</code></a></td>
<td>Multiplies each input vector by a provided weight vector, using element-wise multiplication.</td>
</tr>
<tr class="odd">
<td><a href="reference/sparklyr/latest/ft_index_to_string.html"><code>ft_index_to_string</code></a></td>
<td>Maps a column of label indices back to a column containing the original labels as strings</td>
</tr>
<tr class="even">
<td><a href="reference/sparklyr/latest/ft_quantile_discretizer.html"><code>ft_quantile_discretizer</code></a></td>
<td>Takes a column with continuous features and outputs a column with binned categorical features</td>
</tr>
<tr class="odd">
<td><a href="reference/sparklyr/latest/ft_sql_transformer.html"><code>ft_sql_transformer</code></a></td>
<td>Implements the transformations which are defined by a SQL statement</td>
</tr>
<tr class="even">
<td><a href="reference/sparklyr/latest/ft_string_indexer.html"><code>ft_string_indexer</code></a></td>
<td>Encodes a string column of labels to a column of label indices</td>
</tr>
<tr class="odd">
<td><a href="reference/sparklyr/latest/ft_vector_assembler.html"><code>ft_vector_assembler</code></a></td>
<td>Combines a given list of columns into a single vector column</td>
</tr>
</tbody>
</table>
</div>
<div id="utilities" class="section level2">
<h2>Utilities</h2>
<p>Functions for interacting with Spark ML model fits.</p>
<table>
<colgroup>
<col width="38%">
<col width="61%">
</colgroup>
<thead><tr class="header">
<th>Function</th>
<th>Description</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><a href="http://spark.rstudio.com/reference/sparklyr/latest/ml_binary_classification_eval.html"><code>ml_binary_classification_eval</code></a></td>
<td>Calculates the area under the curve for a binary classification model.</td>
</tr>
<tr class="even">
<td><a href="http://spark.rstudio.com/reference/sparklyr/latest/ml_classification_eval.html"><code>ml_classification_eval</code></a></td>
<td>Calculates performance metrics (i.e. f1, precision, recall, weightedPrecision, weightedRecall, and accuracy) for binary and multiclass classification model.</td>
</tr>
<tr class="odd">
<td><a href="http://spark.rstudio.com/reference/sparklyr/latest/ml_tree_feature_importance.html"><code>ml_tree_feature_importance</code></a></td>
<td>Calculates variable importance for decision trees (i.e. decision trees, random forests, gradient boosted trees).</td>
</tr>
<tr class="even">
<td><a href="http://spark.rstudio.com/reference/sparklyr/latest/ml_saveload.html"><code>ml_saveload</code></a></td>
<td>Save and load model fits. For use with scoring models across platforms (e.g. using a model as an estimator in a Spark application). <em>These functions are currently experimental and not yet ready for production use.</em>
</td>
</tr>
</tbody>
</table>
</div>
<div id="extensions" class="section level2">
<h2>Extensions</h2>
<p>Functions for creating custom wrappers to other Spark ML algorithms.</p>
<table>
<colgroup>
<col width="38%">
<col width="61%">
</colgroup>
<thead><tr class="header">
<th>Function</th>
<th>Description</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><a href="http://spark.rstudio.com/reference/sparklyr/latest/ensure.html"><code>ensure</code></a></td>
<td>Enforces Specific Structure for R Objects.</td>
</tr>
<tr class="even">
<td><a href="http://spark.rstudio.com/reference/sparklyr/latest/ml_create_dummy_variables.html"><code>ml_create_dummy_variables</code></a></td>
<td>Given a column in a Spark DataFrame, generate a new Spark DataFrame containing dummy variable columns.</td>
</tr>
<tr class="odd">
<td><a href="http://spark.rstudio.com/reference/sparklyr/latest/ml_model.html"><code>ml_model</code></a></td>
<td>Creates an ML Model Object.</td>
</tr>
<tr class="even">
<td><a href="http://spark.rstudio.com/reference/sparklyr/latest/ml_options.html"><code>ml_options</code></a></td>
<td>Provides Options for Spark.ML Routines.</td>
</tr>
<tr class="odd">
<td><a href="http://spark.rstudio.com/reference/sparklyr/latest/ml_prepare_dataframe.html"><code>ml_prepare_dataframe</code></a></td>
<td>Prepares a Spark DataFrame for Spark ML Routines.</td>
</tr>
<tr class="even">
<td><a href="http://spark.rstudio.com/reference/sparklyr/latest/ml_prepare_inputs.html"><code>ml_prepare_response_features_intercept</code></a></td>
<td>Pre-process / normalize the inputs typically passed to a Spark ML routine.</td>
</tr>
</tbody>
</table>
</div>
<div id="examples" class="section level2">
<h2>Examples</h2>
<p>We will use the <code>iris</code> data set to examine a handful of learning algorithms and transformers. The iris data set measures attributes for 150 flowers in 3 different species of iris.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(sparklyr)
<span class="kw">library</span>(ggplot2)
<span class="kw">library</span>(dplyr)</code></pre></div>
<pre><code>## 
## Attaching package: 'dplyr'</code></pre>
<pre><code>## The following objects are masked from 'package:stats':
## 
##     filter, lag</code></pre>
<pre><code>## The following objects are masked from 'package:base':
## 
##     intersect, setdiff, setequal, union</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sc &lt;-<span class="st"> </span><span class="kw">spark_connect</span>(<span class="dt">master =</span> <span class="st">"local"</span>)</code></pre></div>
<pre><code>## * Using Spark: 2.1.0</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">iris_tbl &lt;-<span class="st"> </span><span class="kw">copy_to</span>(sc, iris, <span class="st">"iris"</span>, <span class="dt">overwrite =</span> <span class="ot">TRUE</span>)
iris_tbl</code></pre></div>
<pre><code>## # Source:   table&lt;iris&gt; [?? x 5]
## # Database: spark_connection
##    Sepal_Length Sepal_Width Petal_Length Petal_Width Species
##           &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt;   &lt;chr&gt;
##  1          5.1         3.5          1.4         0.2  setosa
##  2          4.9         3.0          1.4         0.2  setosa
##  3          4.7         3.2          1.3         0.2  setosa
##  4          4.6         3.1          1.5         0.2  setosa
##  5          5.0         3.6          1.4         0.2  setosa
##  6          5.4         3.9          1.7         0.4  setosa
##  7          4.6         3.4          1.4         0.3  setosa
##  8          5.0         3.4          1.5         0.2  setosa
##  9          4.4         2.9          1.4         0.2  setosa
## 10          4.9         3.1          1.5         0.1  setosa
## # ... with more rows</code></pre>
<div id="k-means-clustering" class="section level3">
<h3>K-Means Clustering</h3>
<p>Use Spark’s <a href="http://spark.apache.org/docs/latest/ml-clustering.html#k-means">K-means clustering</a> to partition a dataset into groups. K-means clustering partitions points into <code>k</code> groups, such that the sum of squares from points to the assigned cluster centers is minimized.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">kmeans_model &lt;-<span class="st"> </span>iris_tbl <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(Petal_Width, Petal_Length) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ml_kmeans</span>(<span class="dt">centers =</span> <span class="dv">3</span>)</code></pre></div>
<pre><code>## * No rows dropped by 'na.omit' call</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># print our model fit</span>
kmeans_model</code></pre></div>
<pre><code>## K-means clustering with 3 clusters
## 
## Cluster centers:
##   Petal_Width Petal_Length
## 1    1.359259     4.292593
## 2    0.246000     1.462000
## 3    2.047826     5.626087
## 
## Within Set Sum of Squared Errors =  31.41289</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># predict the associated class</span>
predicted &lt;-<span class="st"> </span><span class="kw">sdf_predict</span>(kmeans_model, iris_tbl) <span class="op">%&gt;%</span>
<span class="st">  </span>collect
<span class="kw">table</span>(predicted<span class="op">$</span>Species, predicted<span class="op">$</span>prediction)</code></pre></div>
<pre><code>##             
##               0  1  2
##   setosa      0 50  0
##   versicolor 48  0  2
##   virginica   6  0 44</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># plot cluster membership</span>
<span class="kw">sdf_predict</span>(kmeans_model) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">collect</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(Petal_Length, Petal_Width)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(Petal_Width, Petal_Length, <span class="dt">col =</span> <span class="kw">factor</span>(prediction <span class="op">+</span><span class="st"> </span><span class="dv">1</span>)),
             <span class="dt">size =</span> <span class="dv">2</span>, <span class="dt">alpha =</span> <span class="fl">0.5</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">data =</span> kmeans_model<span class="op">$</span>centers, <span class="kw">aes</span>(Petal_Width, Petal_Length),
             <span class="dt">col =</span> scales<span class="op">::</span><span class="kw"><a href="http://www.rdocumentation.org/packages/scales/topics/muted">muted</a></span>(<span class="kw">c</span>(<span class="st">"red"</span>, <span class="st">"green"</span>, <span class="st">"blue"</span>)),
             <span class="dt">pch =</span> <span class="st">'x'</span>, <span class="dt">size =</span> <span class="dv">12</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_color_discrete</span>(<span class="dt">name =</span> <span class="st">"Predicted Cluster"</span>,
                       <span class="dt">labels =</span> <span class="kw">paste</span>(<span class="st">"Cluster"</span>, <span class="dv">1</span><span class="op">:</span><span class="dv">3</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(
    <span class="dt">x =</span> <span class="st">"Petal Length"</span>,
    <span class="dt">y =</span> <span class="st">"Petal Width"</span>,
    <span class="dt">title =</span> <span class="st">"K-Means Clustering"</span>,
    <span class="dt">subtitle =</span> <span class="st">"Use Spark.ML to predict cluster membership with the iris dataset."</span>
  )</code></pre></div>
<p><img src="/articles/guides-mllib_files/figure-html/unnamed-chunk-5-1.png" width="672"></p>
</div>
<div id="linear-regression" class="section level3">
<h3>Linear Regression</h3>
<p>Use Spark’s <a href="http://spark.apache.org/docs/latest/ml-classification-regression.html#linear-regression">linear regression</a> to model the linear relationship between a response variable and one or more explanatory variables.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lm_model &lt;-<span class="st"> </span>iris_tbl <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(Petal_Width, Petal_Length) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ml_linear_regression</span>(Petal_Length <span class="op">~</span><span class="st"> </span>Petal_Width)</code></pre></div>
<pre><code>## * No rows dropped by 'na.omit' call</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">iris_tbl <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(Petal_Width, Petal_Length) <span class="op">%&gt;%</span>
<span class="st">  </span>collect <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(Petal_Length, Petal_Width)) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(Petal_Width, Petal_Length), <span class="dt">size =</span> <span class="dv">2</span>, <span class="dt">alpha =</span> <span class="fl">0.5</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_abline</span>(<span class="kw">aes</span>(<span class="dt">slope =</span> <span class="kw">coef</span>(lm_model)[[<span class="st">"Petal_Width"</span>]],
                    <span class="dt">intercept =</span> <span class="kw">coef</span>(lm_model)[[<span class="st">"(Intercept)"</span>]]),
                <span class="dt">color =</span> <span class="st">"red"</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(
    <span class="dt">x =</span> <span class="st">"Petal Width"</span>,
    <span class="dt">y =</span> <span class="st">"Petal Length"</span>,
    <span class="dt">title =</span> <span class="st">"Linear Regression: Petal Length ~ Petal Width"</span>,
    <span class="dt">subtitle =</span> <span class="st">"Use Spark.ML linear regression to predict petal length as a function of petal width."</span>
  )</code></pre></div>
<p><img src="/articles/guides-mllib_files/figure-html/unnamed-chunk-6-1.png" width="672"></p>
</div>
<div id="logistic-regression" class="section level3">
<h3>Logistic Regression</h3>
<p>Use Spark’s <a href="http://spark.apache.org/docs/latest/ml-classification-regression.html#logistic-regression">logistic regression</a> to perform logistic regression, modeling a binary outcome as a function of one or more explanatory variables.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Prepare beaver dataset</span>
beaver &lt;-<span class="st"> </span>beaver2
beaver<span class="op">$</span>activ &lt;-<span class="st"> </span><span class="kw">factor</span>(beaver<span class="op">$</span>activ, <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">"Non-Active"</span>, <span class="st">"Active"</span>))
<span class="kw">copy_to</span>(sc, beaver, <span class="st">"beaver"</span>)</code></pre></div>
<pre><code>## # Source:   table&lt;beaver&gt; [?? x 4]
## # Database: spark_connection
##      day  time  temp      activ
##    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;      &lt;chr&gt;
##  1   307   930 36.58 Non-Active
##  2   307   940 36.73 Non-Active
##  3   307   950 36.93 Non-Active
##  4   307  1000 37.15 Non-Active
##  5   307  1010 37.23 Non-Active
##  6   307  1020 37.24 Non-Active
##  7   307  1030 37.24 Non-Active
##  8   307  1040 36.90 Non-Active
##  9   307  1050 36.95 Non-Active
## 10   307  1100 36.89 Non-Active
## # ... with more rows</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">beaver_tbl &lt;-<span class="st"> </span><span class="kw">tbl</span>(sc, <span class="st">"beaver"</span>)

glm_model &lt;-<span class="st"> </span>beaver_tbl <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">binary_response =</span> <span class="kw">as.numeric</span>(activ <span class="op">==</span><span class="st"> "Active"</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ml_logistic_regression</span>(binary_response <span class="op">~</span><span class="st"> </span>temp)</code></pre></div>
<pre><code>## * No rows dropped by 'na.omit' call</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">glm_model</code></pre></div>
<pre><code>## Call: binary_response ~ temp
## 
## Coefficients:
## (Intercept)        temp 
##  -550.52331    14.69184</code></pre>
</div>
<div id="pca" class="section level3">
<h3>PCA</h3>
<p>Use Spark’s <a href="https://spark.apache.org/docs/latest/mllib-dimensionality-reduction.html">Principal Components Analysis (PCA)</a> to perform dimensionality reduction. PCA is a statistical method to find a rotation such that the first coordinate has the largest variance possible, and each succeeding coordinate in turn has the largest variance possible.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pca_model &lt;-<span class="st"> </span><span class="kw">tbl</span>(sc, <span class="st">"iris"</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(<span class="op">-</span>Species) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ml_pca</span>()</code></pre></div>
<pre><code>## * No rows dropped by 'na.omit' call</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(pca_model)</code></pre></div>
<pre><code>## Explained variance:
## 
##         PC1         PC2         PC3         PC4 
## 0.924618723 0.053066483 0.017102610 0.005212184 
## 
## Rotation:
##                      PC1         PC2         PC3        PC4
## Sepal_Length -0.36138659 -0.65658877  0.58202985  0.3154872
## Sepal_Width   0.08452251 -0.73016143 -0.59791083 -0.3197231
## Petal_Length -0.85667061  0.17337266 -0.07623608 -0.4798390
## Petal_Width  -0.35828920  0.07548102 -0.54583143  0.7536574</code></pre>
</div>
<div id="random-forest" class="section level3">
<h3>Random Forest</h3>
<p>Use Spark’s <a href="https://spark.apache.org/docs/latest/ml-classification-regression.html#random-forest-regression">Random Forest</a> to perform regression or multiclass classification.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">rf_model &lt;-<span class="st"> </span>iris_tbl <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ml_random_forest</span>(Species <span class="op">~</span><span class="st"> </span>Petal_Length <span class="op">+</span><span class="st"> </span>Petal_Width, <span class="dt">type =</span> <span class="st">"classification"</span>)</code></pre></div>
<pre><code>## * No rows dropped by 'na.omit' call</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">rf_predict &lt;-<span class="st"> </span><span class="kw">sdf_predict</span>(rf_model, iris_tbl) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ft_string_indexer</span>(<span class="st">"Species"</span>, <span class="st">"Species_idx"</span>) <span class="op">%&gt;%</span>
<span class="st">  </span>collect

<span class="kw">table</span>(rf_predict<span class="op">$</span>Species_idx, rf_predict<span class="op">$</span>prediction)</code></pre></div>
<pre><code>##    
##      0  1  2
##   0 49  1  0
##   1  0 50  0
##   2  0  0 50</code></pre>
</div>
<div id="sdf-partitioning" class="section level3">
<h3>SDF Partitioning</h3>
<p>Split a Spark DataFrame into training, test datasets.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">partitions &lt;-<span class="st"> </span><span class="kw">tbl</span>(sc, <span class="st">"iris"</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">sdf_partition</span>(<span class="dt">training =</span> <span class="fl">0.75</span>, <span class="dt">test =</span> <span class="fl">0.25</span>, <span class="dt">seed =</span> <span class="dv">1099</span>)

fit &lt;-<span class="st"> </span>partitions<span class="op">$</span>training <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ml_linear_regression</span>(Petal_Length <span class="op">~</span><span class="st"> </span>Petal_Width)</code></pre></div>
<pre><code>## * No rows dropped by 'na.omit' call</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">estimate_mse &lt;-<span class="st"> </span><span class="cf">function</span>(df){
  <span class="kw">sdf_predict</span>(fit, df) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">resid =</span> Petal_Length <span class="op">-</span><span class="st"> </span>prediction) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">mse =</span> <span class="kw">mean</span>(resid <span class="op">^</span><span class="st"> </span><span class="dv">2</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span>collect
}

<span class="kw">sapply</span>(partitions, estimate_mse)</code></pre></div>
<pre><code>## $training.mse
## [1] 0.2374596
## 
## $test.mse
## [1] 0.1898848</code></pre>
</div>
<div id="ft-string-indexing" class="section level3">
<h3>FT String Indexing</h3>
<p>Use <code>ft_string_indexer</code> and <code>ft_index_to_string</code> to convert a character column into a numeric column and back again.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ft_string2idx &lt;-<span class="st"> </span>iris_tbl <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ft_string_indexer</span>(<span class="st">"Species"</span>, <span class="st">"Species_idx"</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ft_index_to_string</span>(<span class="st">"Species_idx"</span>, <span class="st">"Species_remap"</span>) <span class="op">%&gt;%</span>
<span class="st">  </span>collect

<span class="kw">table</span>(ft_string2idx<span class="op">$</span>Species, ft_string2idx<span class="op">$</span>Species_remap)</code></pre></div>
<pre><code>##             
##              setosa versicolor virginica
##   setosa         50          0         0
##   versicolor      0         50         0
##   virginica       0          0        50</code></pre>
</div>
<div id="sdf-mutate" class="section level3">
<h3>SDF Mutate</h3>
<p><a href="reference/sparklyr/latest/sdf_mutate.html">sdf_mutate</a> is provided as a helper function, to allow you to use feature transformers. For example, the previous code snippet could have been written as:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ft_string2idx &lt;-<span class="st"> </span>iris_tbl <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">sdf_mutate</span>(<span class="dt">Species_idx =</span> <span class="kw">ft_string_indexer</span>(Species)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">sdf_mutate</span>(<span class="dt">Species_remap =</span> <span class="kw">ft_index_to_string</span>(Species_idx)) <span class="op">%&gt;%</span>
<span class="st">  </span>collect
  
ft_string2idx <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(Species, Species_idx, Species_remap) <span class="op">%&gt;%</span>
<span class="st">  </span>distinct</code></pre></div>
<pre><code>## # A tibble: 3 x 3
##      Species Species_idx Species_remap
##        &lt;chr&gt;       &lt;dbl&gt;         &lt;chr&gt;
## 1     setosa           2        setosa
## 2 versicolor           0    versicolor
## 3  virginica           1     virginica</code></pre>
</div>
<div id="example-workflow" class="section level3">
<h3>Example Workflow</h3>
<p>Let’s walk through a simple example to demonstrate the use of Spark’s machine learning algorithms within R. We’ll use <a href="reference/sparklyr/latest/ml_linear_regression.html">ml_linear_regression</a> to fit a linear regression model. Using the built-in <code>mtcars</code> dataset, we’ll try to predict a car’s fuel consumption (<code>mpg</code>) based on its weight (<code>wt</code>), and the number of cylinders the engine contains (<code>cyl</code>).</p>
<p>First, we will copy the <code>mtcars</code> dataset into Spark.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mtcars_tbl &lt;-<span class="st"> </span><span class="kw">copy_to</span>(sc, mtcars, <span class="st">"mtcars"</span>)</code></pre></div>
<p>Transform the data with Spark SQL, feature transformers, and DataFrame functions.</p>
<ol style="list-style-type: decimal">
<li>Use Spark SQL to remove all cars with horsepower less than 100</li>
<li>Use Spark feature transformers to bucket cars into two groups based on cylinders</li>
<li>Use Spark DataFrame functions to partition the data into test and training</li>
</ol>
<p>Then fit a linear model using spark ML. Model MPG as a function of weight and cylinders.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># transform our data set, and then partition into 'training', 'test'</span>
partitions &lt;-<span class="st"> </span>mtcars_tbl <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(hp <span class="op">&gt;=</span><span class="st"> </span><span class="dv">100</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">sdf_mutate</span>(<span class="dt">cyl8 =</span> <span class="kw">ft_bucketizer</span>(cyl, <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">8</span>,<span class="dv">12</span>))) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">sdf_partition</span>(<span class="dt">training =</span> <span class="fl">0.5</span>, <span class="dt">test =</span> <span class="fl">0.5</span>, <span class="dt">seed =</span> <span class="dv">888</span>)

<span class="co"># fit a linear mdoel to the training dataset</span>
fit &lt;-<span class="st"> </span>partitions<span class="op">$</span>training <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ml_linear_regression</span>(mpg <span class="op">~</span><span class="st"> </span>wt <span class="op">+</span><span class="st"> </span>cyl)</code></pre></div>
<pre><code>## * No rows dropped by 'na.omit' call</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># summarize the model</span>
<span class="kw">summary</span>(fit)</code></pre></div>
<pre><code>## Call: ml_linear_regression(., mpg ~ wt + cyl)
## 
## Deviance Residuals::
##     Min      1Q  Median      3Q     Max 
## -2.0947 -1.2747 -0.1129  1.0876  2.2185 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 33.79558    2.67240 12.6462 4.92e-07 ***
## wt          -1.59625    0.73729 -2.1650  0.05859 .  
## cyl         -1.58036    0.49670 -3.1817  0.01115 *  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## R-Squared: 0.8267
## Root Mean Squared Error: 1.437</code></pre>
<p>The <code>summary()</code> suggests that our model is a fairly good fit, and that both a cars weight, as well as the number of cylinders in its engine, will be powerful predictors of its average fuel consumption. (The model suggests that, on average, heavier cars consume more fuel.)</p>
<p>Let’s use our Spark model fit to predict the average fuel consumption on our test data set, and compare the predicted response with the true measured fuel consumption. We’ll build a simple ggplot2 plot that will allow us to inspect the quality of our predictions.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Score the data</span>
pred &lt;-<span class="st"> </span><span class="kw">sdf_predict</span>(fit, partitions<span class="op">$</span>test) <span class="op">%&gt;%</span>
<span class="st">  </span>collect

<span class="co"># Plot the predicted versus actual mpg</span>
<span class="kw">ggplot</span>(pred, <span class="kw">aes</span>(<span class="dt">x =</span> mpg, <span class="dt">y =</span> prediction)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_abline</span>(<span class="dt">lty =</span> <span class="st">"dashed"</span>, <span class="dt">col =</span> <span class="st">"red"</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">plot.title =</span> <span class="kw">element_text</span>(<span class="dt">hjust =</span> <span class="fl">0.5</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_fixed</span>(<span class="dt">ratio =</span> <span class="dv">1</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(
    <span class="dt">x =</span> <span class="st">"Actual Fuel Consumption"</span>,
    <span class="dt">y =</span> <span class="st">"Predicted Fuel Consumption"</span>,
    <span class="dt">title =</span> <span class="st">"Predicted vs. Actual Fuel Consumption"</span>
  )</code></pre></div>
<p><img src="/articles/guides-mllib_files/figure-html/unnamed-chunk-15-1.png" width="672"></p>
<p>Although simple, our model appears to do a fairly good job of predicting a car’s average fuel consumption.</p>
<p>As you can see, we can easily and effectively combine feature transformers, machine learning algorithms, and Spark DataFrame functions into a complete analysis with Spark and R.</p>
</div>
</div>

      </div>
      
      
<footer>



</footer>
      
    </div>
</div>

</body>
</html>

