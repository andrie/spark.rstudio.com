<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>All news • sparklyr</title>

<!-- jquery -->
<script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script>
<!-- Bootstrap -->
<link href="https://maxcdn.bootstrapcdn.com/bootswatch/3.3.7/cosmo/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">

<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>

<!-- Font Awesome icons -->
<link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">


<!-- pkgdown -->
<link href="../pkgdown.css" rel="stylesheet">
<script src="../jquery.sticky-kit.min.js"></script>
<script src="../pkgdown.js"></script>

<!-- mathjax -->
<script src='https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
  </head>

  <body>
    <div class="container template-news">
      <header>
      <div class="navbar navbar-inverse navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">sparklyr</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="../index.html">Home</a>
</li>
<li>
  <a href="../dplyr.html">dplyr</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    ML
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="../mllib.html">Spark MLlib</a>
    </li>
    <li>
      <a href="../h2o.html">H2O</a>
    </li>
  </ul>
</li>
<li>
  <a href="../extensions.html">Extensions</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Deployment
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="../deployment.html">Configuration</a>
    </li>
    <li>
      <a href="../deployment_examples.html">Deployment Examples</a>
    </li>
  </ul>
</li>
<li>
  <a href="../examples.html">Examples</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Reference
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="../reference/index.html">Function Reference</a>
    </li>
    <li>
      <a href="../news/index.html">News</a>
    </li>
    <li>
      <a href="../images/sparklyr-cheatsheet.pdf">Cheatsheet</a>
    </li>
    <li>
      <a href="../other-resources.html">Additional Resources</a>
    </li>
  </ul>
</li>
      </ul>
      
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/rstudio/sparklyr">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      
      </header>

      <div class="row">

  <div class="col-md-9">
    <div class="page-header">
      <h1>Change log <small>All releases</small></h1>
    </div>

    <div class="contents">
    <div id="sparklyr-0-6-0-unreleased" class="section level1">
<h1 class="hasAnchor">
<a href="#sparklyr-0-6-0-unreleased" class="anchor"> </a>Sparklyr 0.6.0 (UNRELEASED)</h1>
<ul><li><p><code>sample_frac</code> takes a fraction instead of a percent to match <code>dplyr</code>.</p></li>
<li><p>Improved performance of <code>spark_read_csv</code> reading remote data when <code>infer_schema = FALSE</code>.</p></li>
<li><p>Added <code>spark_read_jdbc</code>. This function reads from a JDBC connection into a Spark DataFrame.</p></li>
<li><p>Renamed <code>spark_load_table</code> and <code>spark_save_table</code> into <code>spark_read_table</code> and <code>spark_write_table</code> for consistency with existing <code>spark_read_*</code> and <code>spark_write_*</code> functions.</p></li>
<li><p>Added <code>src_databases</code>. This function list all the available databases.</p></li>
<li><p>Improved support in dplyr commands to handle multiple databases.</p></li>
<li><p>Implemented new configuration checks to proactively report connection errors in Windows.</p></li>
<li><p>While connecting to spark from Windows, setting the <code>sparklyr.verbose</code> option to <code>TRUE</code> prints detailed configuration steps.</p></li>
<li><p>Added support to specify a vector of column names in <code>spark_read_csv</code> to specify column names without having to set the type of each column.</p></li>
<li><p>Improved <code>copy_to</code>, <code>sdf_copy_to</code> and <code>dbWriteTable</code> performance under <code>yarn-client</code> mode.</p></li>
<li><p>Added <code>tbl_change_tb()</code>. This function changes current database.</p></li>
<li><p>Added <code><a href="../reference/sdf_pivot.html">sdf_pivot()</a></code>. This function provides a mechanism for constructing pivot tables, using Spark’s ‘groupBy’ + ‘pivot’ functionality, with a formula interface similar to that of <code>reshape2::dcast()</code>.</p></li>
<li><p>Spark Null objects (objects of class NullType) discovered within numeric vectors are now collected as NAs, rather than lists of NAs.</p></li>
<li><p>Fixed warning while connecting with livy and improved 401 message.</p></li>
<li><p>Fixed issue in <code><a href="../reference/spark_read_parquet.html">spark_read_parquet()</a></code> and other read methods in which <code>spark_normalize_path()</code> would not work in some platforms while loading data using custom protocols like s3n:// for Amazon S3.</p></li>
<li><p>Added <code><a href="../reference/ft_count_vectorizer.html">ft_count_vectorizer()</a></code>. This function can be used to transform columns of a Spark DataFrame so that they might be used as input to <code><a href="../reference/ml_lda.html">ml_lda()</a></code>. This should make it easier to invoke <code><a href="../reference/ml_lda.html">ml_lda()</a></code> on Spark data sets.</p></li>
<li><p>Added support for the <code>sparklyr.ui.connections</code> option, which adds additional connection options into the new connections dialog. The <code>rstudio.spark.connections</code> option is now deprecated.</p></li>
<li><p>Implemented the “new connection dialog” as a Shiny application to be able to support newer versions of RStudio that deprecate current connections ui.</p></li>
<li><p>Improved performance of <code>sample_n()</code> and <code>sample_frac()</code> by using TABLESAMPLE query.</p></li>
<li><p>Resolved issue in <code>spark_save()</code> / <code>load_table()</code> to support saving / loading data and added path parameter in <code><a href="../reference/spark_load_table.html">spark_load_table()</a></code> for consistency with other functions.</p></li>
</ul></div>
    <div id="sparklyr-0-5-0" class="section level1">
<h1 class="hasAnchor">
<a href="#sparklyr-0-5-0" class="anchor"> </a>Sparklyr 0.5.0</h1>
<ul><li><p>Implemented basic authorization for Livy connections using <code>livy_config_auth()</code>.</p></li>
<li><p>Added support to specify additional <code>spark-submit</code> parameters using the <code>sparklyr.shell.args</code> environment variable.</p></li>
<li><p>Renamed <code>sdf_load()</code> and <code>sdf_save()</code> to <code>spark_read()</code> and <code>spark_write()</code> for consistency.</p></li>
<li><p>The functions <code><a href="../reference/tbl_cache.html">tbl_cache()</a></code> and <code><a href="../reference/tbl_uncache.html">tbl_uncache()</a></code> can now be using without requiring the <code>dplyr</code> namespace to be loaded.</p></li>
<li><p><code>spark_read_csv(..., columns = &lt;...&gt;, header = FALSE)</code> should now work as expected – previously, <code>sparklyr</code> would still attempt to normalize the column names provided.</p></li>
<li><p>Support to configure Livy using the <code>livy.</code> prefix in the <code>config.yml</code> file.</p></li>
<li><p>Implemented experimental support for Livy through: <code><a href="../reference/livy_install.html">livy_install()</a></code>, <code><a href="../reference/livy_service_start.html">livy_service_start()</a></code>, <code><a href="../reference/livy_service_start.html">livy_service_stop()</a></code> and <code><a href="../reference/spark-connections.html">spark_connect(method = "livy")</a></code>.</p></li>
<li><p>The <code>ml</code> routines now accept <code>data</code> as an optional argument, to support calls of the form e.g. <code><a href="../reference/ml_linear_regression.html">ml_linear_regression(y ~ x, data = data)</a></code>. This should be especially helpful in conjunction with <code>dplyr::do()</code>.</p></li>
<li><p>Spark <code>DenseVector</code> and <code>SparseVector</code> objects are now deserialized as R numeric vectors, rather than Spark objects. This should make it easier to work with the output produced by <code><a href="../reference/sdf_predict.html">sdf_predict()</a></code> with Random Forest models, for example.</p></li>
<li><p>Implemented <code>dim.tbl_spark()</code>. This should ensure that <code>dim()</code>, <code>nrow()</code> and <code>ncol()</code> all produce the expected result with <code>tbl_spark</code>s.</p></li>
<li><p>Improved Spark 2.0 installation in Windows by creating <code>spark-defaults.conf</code> and configuring <code>spark.sql.warehouse.dir</code>.</p></li>
<li><p>Embedded Apache Spark package dependencies to avoid requiring internet connectivity while connecting for the first through <code>spark_connect</code>. The <code>sparklyr.csv.embedded</code> config setting was added to configure a regular expression to match Spark versions where the embedded package is deployed.</p></li>
<li><p>Increased exception callstack and message length to include full error details when an exception is thrown in Spark.</p></li>
<li><p>Improved validation of supported Java versions.</p></li>
<li><p>The <code><a href="../reference/spark_read_csv.html">spark_read_csv()</a></code> function now accepts the <code>infer_schema</code> parameter, controlling whether the columns schema should be inferred from the underlying file itself. Disabling this should improve performance when the schema is known beforehand.</p></li>
<li><p>Added a <code>do_.tbl_spark</code> implementation, allowing for the execution of <code>dplyr::do</code> statements on Spark DataFrames. Currently, the computation is performed in serial across the different groups specified on the Spark DataFrame; in the future we hope to explore a parallel implementation. Note that <code>do_</code> always returns a <code>tbl_df</code> rather than a <code>tbl_spark</code>, as the objects produced within a <code>do_</code> query may not necessarily be Spark objects.</p></li>
<li><p>Improved errors, warnings and fallbacks for unsupported Spark versions.</p></li>
<li><p><code>sparklyr</code> now defaults to <code>tar = "internal"</code> in its calls to <code>untar()</code>. This should help resolve issues some Windows users have seen related to an inability to connect to Spark, which ultimately were caused by a lack of permissions on the Spark installation.</p></li>
<li><p>Resolved an issue where <code><a href="../reference/reexports.html">copy_to()</a></code> and other R =&gt; Spark data transfer functions could fail when the last column contained missing / empty values. (#265)</p></li>
<li><p>Added <code><a href="../reference/sdf_persist.html">sdf_persist()</a></code> as a wrapper to the Spark DataFrame <code>persist()</code> API.</p></li>
<li><p>Resolved an issue where <code>predict()</code> could produce results in the wrong order for large Spark DataFrames.</p></li>
<li><p>Implemented support for <code>na.action</code> with the various Spark ML routines. The value of <code>getOption("na.action")</code> is used by default. Users can customize the <code>na.action</code> argument through the <code>ml.options</code> object accepted by all ML routines.</p></li>
<li><p>On Windows, long paths, and paths containing spaces, are now supported within calls to <code><a href="../reference/spark-connections.html">spark_connect()</a></code>.</p></li>
<li><p>The <code>lag()</code> window function now accepts numeric values for <code>n</code>. Previously, only integer values were accepted. (#249)</p></li>
<li><p>Added support to configure Ppark environment variables using <code>spark.env.*</code> config.</p></li>
<li><p>Added support for the <code>Tokenizer</code> and <code>RegexTokenizer</code> feature transformers. These are exported as the <code><a href="../reference/ft_tokenizer.html">ft_tokenizer()</a></code> and <code><a href="../reference/ft_regex_tokenizer.html">ft_regex_tokenizer()</a></code> functions.</p></li>
<li><p>Resolved an issue where attempting to call <code><a href="../reference/reexports.html">copy_to()</a></code> with an R <code>data.frame</code> containing many columns could fail with a Java StackOverflow. (#244)</p></li>
<li><p>Resolved an issue where attempting to call <code>collect()</code> on a Spark DataFrame containing many columns could produce the wrong result. (#242)</p></li>
<li><p>Added support to parameterize network timeouts using the <code>sparklyr.backend.timeout</code>, <code>sparklyr.gateway.start.timeout</code> and <code>sparklyr.gateway.connect.timeout</code> config settings.</p></li>
<li><p>Improved logging while establishing connections to <code>sparklyr</code>.</p></li>
<li><p>Added <code>sparklyr.gateway.port</code> and <code>sparklyr.gateway.address</code> as config settings.</p></li>
<li><p>The <code><a href="../reference/spark_log.html">spark_log()</a></code> function now accepts the <code>filter</code> parameter. This can be used to filter entries within the Spark log.</p></li>
<li><p>Increased network timeout for <code>sparklyr.backend.timeout</code>.</p></li>
<li><p>Moved <code>spark.jars.default</code> setting from options to Spark config.</p></li>
<li><p><code>sparklyr</code> now properly respects the Hive metastore directory with the <code><a href="../reference/sdf-saveload.html">sdf_save_table()</a></code> and <code><a href="../reference/sdf-saveload.html">sdf_load_table()</a></code> APIs for Spark &lt; 2.0.0.</p></li>
<li><p>Added <code><a href="../reference/sdf_quantile.html">sdf_quantile()</a></code> as a means of computing (approximate) quantiles for a column of a Spark DataFrame.</p></li>
<li><p>Added support for <code>n_distinct(...)</code> within the <code>dplyr</code> interface, based on call to Hive function <code>count(DISTINCT ...)</code>. (#220)</p></li>
</ul></div>
    <div id="sparklyr-0-4-0" class="section level1">
<h1 class="hasAnchor">
<a href="#sparklyr-0-4-0" class="anchor"> </a>Sparklyr 0.4.0</h1>
<ul><li>First release to CRAN.</li>
</ul></div>
    </div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
    <div id="tocnav">
      <h2>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
        <li><a href="#sparklyr-0-6-0-unreleased">0.6.0</a></li>
        <li><a href="#sparklyr-0-5-0">0.5.0</a></li>
        <li><a href="#sparklyr-0-4-0">0.4.0</a></li>
      </ul>
    </div>
  </div>

</div>

      <footer>
      <div class="copyright">
  <p>Developed by Javier Luraschi, Kevin Ushey, JJ Allaire,  The Apache Software Foundation.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer>
   </div>

  </body>
</html>
