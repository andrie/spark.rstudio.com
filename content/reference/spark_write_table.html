---
title: "Writes a Spark DataFrame into a Spark table"
aliases:
  - reference/sparklyr/latest/spark_write_table
---

    <div class="doc-page">

    <div class="doc-page-index">
    <ul data-gumshoe>
    <li><a href="#arguments">Arguments</a></li>
    
    <li><a href="#see-also">See also</a></li>
        </ul>
    </div>

    <div class="doc-page-body">

    
    <p>Writes a Spark DataFrame into a Spark table.</p>
    

    <div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class='fu'>spark_write_table</span>(<span class='no'>x</span>, <span class='no'>name</span>, <span class='kw'>mode</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>options</span> <span class='kw'>=</span> <span class='fu'>list</span>(),
  <span class='kw'>partition_by</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='no'>...</span>)</code></pre></div>
    
    <h2 id="arguments">Arguments</h2>
    <table class="ref-arguments">

    <colgroup>
      <col class="name" />
      <col class="desc" />
    </colgroup>

    <tr>
      <td>x</td>
      <td><p>A Spark DataFrame or dplyr operation</p></td>
    </tr>
    <tr>
      <td>name</td>
      <td><p>The name to assign to the newly generated table.</p></td>
    </tr>
    <tr>
      <td>mode</td>
      <td><p>A <code>character</code> element. Specifies the behavior when data or
  table already exists. Supported values include: 'error', 'append', 'overwrite' and
  ignore. Notice that 'overwrite' will also change the column structure.</p>
<p>For more details see also <a href='http://spark.apache.org/docs/latest/sql-programming-guide#save-modes'>http://spark.apache.org/docs/latest/sql-programming-guide#save-modes</a>
  for your version of Spark.</p></td>
    </tr>
    <tr>
      <td>options</td>
      <td><p>A list of strings with additional options.</p></td>
    </tr>
    <tr>
      <td>partition_by</td>
      <td><p>A <code>character</code> vector. Partitions the output by the given columns on the file system.</p></td>
    </tr>
    <tr>
      <td>...</td>
      <td><p>Optional arguments; currently unused.</p></td>
    </tr>
    </table>
    
    <h2 id="see-also">See also</h2>

    <p>Other Spark serialization routines: <code><a href='spark_load_table'>spark_load_table</a></code>,
  <code><a href='spark_read_csv'>spark_read_csv</a></code>,
  <code><a href='spark_read_jdbc'>spark_read_jdbc</a></code>,
  <code><a href='spark_read_json'>spark_read_json</a></code>,
  <code><a href='spark_read_libsvm'>spark_read_libsvm</a></code>,
  <code><a href='spark_read_parquet'>spark_read_parquet</a></code>,
  <code><a href='spark_read_source'>spark_read_source</a></code>,
  <code><a href='spark_read_table'>spark_read_table</a></code>,
  <code><a href='spark_read_text'>spark_read_text</a></code>,
  <code><a href='spark_save_table'>spark_save_table</a></code>,
  <code><a href='spark_write_csv'>spark_write_csv</a></code>,
  <code><a href='spark_write_jdbc'>spark_write_jdbc</a></code>,
  <code><a href='spark_write_json'>spark_write_json</a></code>,
  <code><a href='spark_write_parquet'>spark_write_parquet</a></code>,
  <code><a href='spark_write_source'>spark_write_source</a></code>,
  <code><a href='spark_write_text'>spark_write_text</a></code></p>
    

    </div>

    </div>

