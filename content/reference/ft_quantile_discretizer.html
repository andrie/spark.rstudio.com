---
title: "Feature Transformation -- QuantileDiscretizer (Estimator)"
aliases:
  - reference/sparklyr/latest/ft_quantile_discretizer
---

    <div class="doc-page">

    <div class="doc-page-index">
    <ul data-gumshoe>
    <li><a href="#arguments">Arguments</a></li>
    
    <li><a href="#value">Value</a></li>

    <li><a href="#details">Details</a></li>

    <li><a href="#see-also">See also</a></li>
        </ul>
    </div>

    <div class="doc-page-body">

    
    <p><code>ft_quantile_discretizer</code> takes a column with continuous features and outputs
  a column with binned categorical features. The number of bins can be
  set using the <code>num_buckets</code> parameter. It is possible that the number
  of buckets used will be smaller than this value, for example, if there
  are too few distinct values of the input to create enough distinct
  quantiles.</p>
    

    <div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class='fu'>ft_quantile_discretizer</span>(<span class='no'>x</span>, <span class='no'>input_col</span>, <span class='no'>output_col</span>, <span class='kw'>handle_invalid</span> <span class='kw'>=</span> <span class='st'>"error"</span>,
  <span class='kw'>num_buckets</span> <span class='kw'>=</span> <span class='fl'>2L</span>, <span class='kw'>relative_error</span> <span class='kw'>=</span> <span class='fl'>0.001</span>, <span class='kw'>dataset</span> <span class='kw'>=</span> <span class='kw'>NULL</span>,
  <span class='kw'>uid</span> <span class='kw'>=</span> <span class='fu'><a href='random_string'>random_string</a></span>(<span class='st'>"quantile_discretizer_"</span>), <span class='no'>...</span>)</code></pre></div>
    
    <h2 id="arguments">Arguments</h2>
    <table class="ref-arguments">

    <colgroup>
      <col class="name" />
      <col class="desc" />
    </colgroup>

    <tr>
      <td>x</td>
      <td><p>A <code>spark_connection</code>, <code>ml_pipeline</code>, or a <code>tbl_spark</code>.</p></td>
    </tr>
    <tr>
      <td>input_col</td>
      <td><p>The name of the input column.</p></td>
    </tr>
    <tr>
      <td>output_col</td>
      <td><p>The name of the output column.</p></td>
    </tr>
    <tr>
      <td>handle_invalid</td>
      <td><p>(Spark 2.1.0+) Param for how to handle invalid entries. Options are
'skip' (filter out rows with invalid values), 'error' (throw an error), or
'keep' (keep invalid values in a special additional bucket). Default: "error"</p></td>
    </tr>
    <tr>
      <td>num_buckets</td>
      <td><p>Number of buckets (quantiles, or categories) into which data
points are grouped. Must be greater than or equal to 2.</p></td>
    </tr>
    <tr>
      <td>relative_error</td>
      <td><p>(Spark 2.0.0+) Relative error (see documentation for
org.apache.spark.sql.DataFrameStatFunctions.approxQuantile
<a href='https://spark.apache.org/docs/latest/api/scala/index#org.apache.spark.sql.DataFrameStatFunctions'>here</a>
for description). Must be in the range [0, 1]. default: 0.001</p></td>
    </tr>
    <tr>
      <td>dataset</td>
      <td><p>(Optional) A <code>tbl_spark</code>. If provided, eagerly fit the (estimator)
feature "transformer" against <code>dataset</code>. See details.</p></td>
    </tr>
    <tr>
      <td>uid</td>
      <td><p>A character string used to uniquely identify the feature transformer.</p></td>
    </tr>
    <tr>
      <td>...</td>
      <td><p>Optional arguments; currently unused.</p></td>
    </tr>
    </table>
    
    <h2 id="value">Value</h2>

    <p>The object returned depends on the class of <code>x</code>.</p><ul>
<li><p><code>spark_connection</code>: When <code>x</code> is a <code>spark_connection</code>, the function returns a <code>ml_transformer</code>,
  a <code>ml_estimator</code>, or one of their subclasses. The object contains a pointer to
  a Spark <code>Transformer</code> or <code>Estimator</code> object and can be used to compose
  <code>Pipeline</code> objects.</p></li>
<li><p><code>ml_pipeline</code>: When <code>x</code> is a <code>ml_pipeline</code>, the function returns a <code>ml_pipeline</code> with
  the transformer or estimator appended to the pipeline.</p></li>
<li><p><code>tbl_spark</code>: When <code>x</code> is a <code>tbl_spark</code>, a transformer is constructed then
  immediately applied to the input <code>tbl_spark</code>, returning a <code>tbl_spark</code></p></li>
</ul>

    
    <h2 id="details">Details</h2>

    <p>NaN handling: null and NaN values will be ignored from the column
  during <code>QuantileDiscretizer</code> fitting. This will produce a <code>Bucketizer</code>
  model for making predictions. During the transformation, <code>Bucketizer</code>
  will raise an error when it finds NaN values in the dataset, but the
  user can also choose to either keep or remove NaN values within the
  dataset by setting <code>handle_invalid</code> If the user chooses to keep NaN values,
  they will be handled specially and placed into their own bucket,
  for example, if 4 buckets are used, then non-NaN data will be put
  into buckets[0-3], but NaNs will be counted in a special bucket[4].</p>
<p>Algorithm: The bin ranges are chosen using an approximate algorithm (see
  the documentation for org.apache.spark.sql.DataFrameStatFunctions.approxQuantile
  <a href='https://spark.apache.org/docs/latest/api/scala/index#org.apache.spark.sql.DataFrameStatFunctions'>here</a> for a detailed description). The precision of the approximation can be
  controlled with the <code>relative_error</code> parameter. The lower and upper bin
  bounds will be -Infinity and +Infinity, covering all real values.</p>
<p>Note that the result may be different every time you run it, since the sample
  strategy behind it is non-deterministic.</p>
<p>When <code>dataset</code> is provided for an estimator transformer, the function
  internally calls <code><a href='ml-transform-methods'>ml_fit()</a></code> against <code>dataset</code>. Hence, the methods for
  <code>spark_connection</code> and <code>ml_pipeline</code> will then return a <code>ml_transformer</code>
  and a <code>ml_pipeline</code> with a <code>ml_transformer</code> appended, respectively. When
  <code>x</code> is a <code>tbl_spark</code>, the estimator will be fit against <code>dataset</code> before
  transforming <code>x</code>.</p>
<p>When <code>dataset</code> is not specified, the constructor returns a <code>ml_estimator</code>, and,
  in the case where <code>x</code> is a <code>tbl_spark</code>, the estimator fits against <code>x</code> then
  to obtain a transformer, which is then immediately used to transform <code>x</code>.</p>
    
    <h2 id="see-also">See also</h2>

    <p>See <a href='http://spark.apache.org/docs/latest/ml-features'>http://spark.apache.org/docs/latest/ml-features</a> for
  more information on the set of transformations available for DataFrame
  columns in Spark.
    <code><a href='ft_bucketizer'>ft_bucketizer</a></code></p>
<p>Other feature transformers: <code><a href='ft_binarizer'>ft_binarizer</a></code>,
  <code><a href='ft_bucketizer'>ft_bucketizer</a></code>,
  <code><a href='ft_chisq_selector'>ft_chisq_selector</a></code>,
  <code><a href='ft_count_vectorizer'>ft_count_vectorizer</a></code>, <code><a href='ft_dct'>ft_dct</a></code>,
  <code><a href='ft_elementwise_product'>ft_elementwise_product</a></code>,
  <code><a href='ft_hashing_tf'>ft_hashing_tf</a></code>, <code><a href='ft_idf'>ft_idf</a></code>,
  <code><a href='ft_imputer'>ft_imputer</a></code>,
  <code><a href='ft_index_to_string'>ft_index_to_string</a></code>,
  <code><a href='ft_interaction'>ft_interaction</a></code>, <code><a href='ft_lsh'>ft_lsh</a></code>,
  <code><a href='ft_max_abs_scaler'>ft_max_abs_scaler</a></code>,
  <code><a href='ft_min_max_scaler'>ft_min_max_scaler</a></code>, <code><a href='ft_ngram'>ft_ngram</a></code>,
  <code><a href='ft_normalizer'>ft_normalizer</a></code>,
  <code><a href='ft_one_hot_encoder'>ft_one_hot_encoder</a></code>, <code><a href='ft_pca'>ft_pca</a></code>,
  <code><a href='ft_polynomial_expansion'>ft_polynomial_expansion</a></code>,
  <code><a href='ft_r_formula'>ft_r_formula</a></code>,
  <code><a href='ft_regex_tokenizer'>ft_regex_tokenizer</a></code>,
  <code><a href='sql-transformer'>ft_sql_transformer</a></code>,
  <code><a href='ft_standard_scaler'>ft_standard_scaler</a></code>,
  <code><a href='ft_stop_words_remover'>ft_stop_words_remover</a></code>,
  <code><a href='ft_string_indexer'>ft_string_indexer</a></code>,
  <code><a href='ft_tokenizer'>ft_tokenizer</a></code>,
  <code><a href='ft_vector_assembler'>ft_vector_assembler</a></code>,
  <code><a href='ft_vector_indexer'>ft_vector_indexer</a></code>,
  <code><a href='ft_vector_slicer'>ft_vector_slicer</a></code>, <code><a href='ft_word2vec'>ft_word2vec</a></code></p>
    

    </div>

    </div>

