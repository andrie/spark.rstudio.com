---
title: ""
menu:
  main:
    name: "Reference"
    weight: 100
---
    <h1 class = "content-header">Function Reference</h1>

    <div class="doc-page">

    <div class="doc-page-index">
    <ul data-gumshoe>
      <li><a href="#section-spark-operations">Spark Operations</a></li>
      <li><a href="#section-spark-data">Spark Data</a></li>
      <li><a href="#section-spark-tables">Spark Tables</a></li>
      <li><a href="#section-spark-dataframes">Spark DataFrames</a></li>
      <li><a href="#section-spark-machine-learning">Spark Machine Learning</a></li>
      <li><a href="#section-spark-feature-transformers">Spark Feature Transformers</a></li>
      <li><a href="#section-spark-machine-learning-utilities">Spark Machine Learning Utilities</a></li>
      <li><a href="#section-extensions">Extensions</a></li>
      <li><a href="#section-distributed-computing">Distributed Computing</a></li>
    </ul>
    </div>

    <div class="doc-page-body">

      <table class="ref-index">

      <colgroup>
        <col class="alias" />
        <col class="title" />
      </colgroup>

      <tbody>
        <tr>
          <th colspan="2">
            <h2 id="section-spark-operations" class="hasAnchor"><a href="#section-spark-operations" class="anchor"></a>Spark Operations</h2>
            <p class="section-desc"></p>
          </th>
        </tr>
        <tr>
          <!--  -->
          <td>
            <p><code><a href="spark_config">spark_config</a></code> </p>
          </td>
          <td><p>Read Spark Configuration</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark-connections">spark_connect</a></code> <code><a href="spark-connections">spark_connection_is_open</a></code> <code><a href="spark-connections">spark_disconnect</a></code> <code><a href="spark-connections">spark_disconnect_all</a></code> </p>
          </td>
          <td><p>Manage Spark Connections</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_install">spark_install_find</a></code> <code><a href="spark_install">spark_install</a></code> <code><a href="spark_install">spark_uninstall</a></code> <code><a href="spark_install">spark_install_dir</a></code> <code><a href="spark_install">spark_install_tar</a></code> <code><a href="spark_install">spark_installed_versions</a></code> <code><a href="spark_install">spark_available_versions</a></code> </p>
          </td>
          <td><p>Find a given Spark installation by version.</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_log">spark_log</a></code> </p>
          </td>
          <td><p>View Entries in the Spark Log</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_web">spark_web</a></code> </p>
          </td>
          <td><p>Open the Spark web interface</p></td>
        </tr>
      </tbody><tbody>
        <tr>
          <th colspan="2">
            <h2 id="section-spark-data" class="hasAnchor"><a href="#section-spark-data" class="anchor"></a>Spark Data</h2>
            <p class="section-desc"></p>
          </th>
        </tr>
        <tr>
          <!--  -->
          <td>
            <p><code><a href="spark_read_csv">spark_read_csv</a></code> </p>
          </td>
          <td><p>Read a CSV file into a Spark DataFrame</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_read_jdbc">spark_read_jdbc</a></code> </p>
          </td>
          <td><p>Read from JDBC connection into a Spark DataFrame.</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_read_json">spark_read_json</a></code> </p>
          </td>
          <td><p>Read a JSON file into a Spark DataFrame</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_read_parquet">spark_read_parquet</a></code> </p>
          </td>
          <td><p>Read a Parquet file into a Spark DataFrame</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_read_source">spark_read_source</a></code> </p>
          </td>
          <td><p>Read from a generic source into a Spark DataFrame.</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_read_table">spark_read_table</a></code> </p>
          </td>
          <td><p>Reads from a Spark Table into a Spark DataFrame.</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_write_csv">spark_write_csv</a></code> </p>
          </td>
          <td><p>Write a Spark DataFrame to a CSV</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_write_jdbc">spark_write_jdbc</a></code> </p>
          </td>
          <td><p>Writes a Spark DataFrame into a JDBC table</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_write_json">spark_write_json</a></code> </p>
          </td>
          <td><p>Write a Spark DataFrame to a JSON file</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_write_parquet">spark_write_parquet</a></code> </p>
          </td>
          <td><p>Write a Spark DataFrame to a Parquet file</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_write_source">spark_write_source</a></code> </p>
          </td>
          <td><p>Writes a Spark DataFrame into a generic source</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_write_table">spark_write_table</a></code> </p>
          </td>
          <td><p>Writes a Spark DataFrame into a Spark table</p></td>
        </tr>
      </tbody><tbody>
        <tr>
          <th colspan="2">
            <h2 id="section-spark-tables" class="hasAnchor"><a href="#section-spark-tables" class="anchor"></a>Spark Tables</h2>
            <p class="section-desc"></p>
          </th>
        </tr>
        <tr>
          <!--  -->
          <td>
            <p><code><a href="src_databases">src_databases</a></code> </p>
          </td>
          <td><p>Show database list</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="tbl_cache">tbl_cache</a></code> </p>
          </td>
          <td><p>Cache a Spark Table</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="tbl_change_db">tbl_change_db</a></code> </p>
          </td>
          <td><p>Use specific database</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="tbl_uncache">tbl_uncache</a></code> </p>
          </td>
          <td><p>Uncache a Spark Table</p></td>
        </tr>
      </tbody><tbody>
        <tr>
          <th colspan="2">
            <h2 id="section-spark-dataframes" class="hasAnchor"><a href="#section-spark-dataframes" class="anchor"></a>Spark DataFrames</h2>
            <p class="section-desc"></p>
          </th>
        </tr>
        <tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_along">sdf_along</a></code> </p>
          </td>
          <td><p>Create DataFrame for along Object</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_bind">sdf_bind_rows</a></code> <code><a href="sdf_bind">sdf_bind_cols</a></code> </p>
          </td>
          <td><p>Bind multiple Spark DataFrames by row and column</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_broadcast">sdf_broadcast</a></code> </p>
          </td>
          <td><p>Broadcast hint</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_checkpoint">sdf_checkpoint</a></code> </p>
          </td>
          <td><p>Checkpoint a Spark DataFrame</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_coalesce">sdf_coalesce</a></code> </p>
          </td>
          <td><p>Coalesces a Spark DataFrame</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_copy_to">sdf_copy_to</a></code> <code><a href="sdf_copy_to">sdf_import</a></code> </p>
          </td>
          <td><p>Copy an Object into Spark</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_len">sdf_len</a></code> </p>
          </td>
          <td><p>Create DataFrame for Length</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_mutate">sdf_mutate</a></code> <code><a href="sdf_mutate">sdf_mutate_</a></code> </p>
          </td>
          <td><p>Mutate a Spark DataFrame</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_num_partitions">sdf_num_partitions</a></code> </p>
          </td>
          <td><p>Gets number of partitions of a Spark DataFrame</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_partition">sdf_partition</a></code> </p>
          </td>
          <td><p>Partition a Spark Dataframe</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_pivot">sdf_pivot</a></code> </p>
          </td>
          <td><p>Pivot a Spark DataFrame</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf-transform-methods">sdf_predict</a></code> <code><a href="sdf-transform-methods">sdf_transform</a></code> <code><a href="sdf-transform-methods">sdf_fit</a></code> <code><a href="sdf-transform-methods">sdf_fit_and_transform</a></code> </p>
          </td>
          <td><p>Spark ML -- Transform, fit, and predict methods (sdf_ interface)</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_read_column">sdf_read_column</a></code> </p>
          </td>
          <td><p>Read a Column from a Spark DataFrame</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_register">sdf_register</a></code> </p>
          </td>
          <td><p>Register a Spark DataFrame</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_repartition">sdf_repartition</a></code> </p>
          </td>
          <td><p>Repartition a Spark DataFrame</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_residuals">sdf_residuals</a></code> </p>
          </td>
          <td><p>Model Residuals</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_sample">sdf_sample</a></code> </p>
          </td>
          <td><p>Randomly Sample Rows from a Spark DataFrame</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_separate_column">sdf_separate_column</a></code> </p>
          </td>
          <td><p>Separate a Vector Column into Scalar Columns</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_seq">sdf_seq</a></code> </p>
          </td>
          <td><p>Create DataFrame for Range</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_sort">sdf_sort</a></code> </p>
          </td>
          <td><p>Sort a Spark DataFrame</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_with_unique_id">sdf_with_unique_id</a></code> </p>
          </td>
          <td><p>Add a Unique ID Column to a Spark DataFrame</p></td>
        </tr>
      </tbody><tbody>
        <tr>
          <th colspan="2">
            <h2 id="section-spark-machine-learning" class="hasAnchor"><a href="#section-spark-machine-learning" class="anchor"></a>Spark Machine Learning</h2>
            <p class="section-desc"></p>
          </th>
        </tr>
        <tr>
          <!--  -->
          <td>
            <p><code><a href="ml_als">ml_als</a></code> <code><a href="ml_als">ml_recommend</a></code> <code><a href="ml_als">ml_als_factorization</a></code> </p>
          </td>
          <td><p>Spark ML -- ALS</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ml_decision_tree">ml_decision_tree_classifier</a></code> <code><a href="ml_decision_tree">ml_decision_tree</a></code> <code><a href="ml_decision_tree">ml_decision_tree_regressor</a></code> </p>
          </td>
          <td><p>Spark ML -- Decision Trees</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ml_generalized_linear_regression">ml_generalized_linear_regression</a></code> </p>
          </td>
          <td><p>Spark ML -- Generalized Linear Regression</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ml_gradient_boosted_trees">ml_gbt_classifier</a></code> <code><a href="ml_gradient_boosted_trees">ml_gradient_boosted_trees</a></code> <code><a href="ml_gradient_boosted_trees">ml_gbt_regressor</a></code> </p>
          </td>
          <td><p>Spark ML -- Gradient Boosted Trees</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ml_kmeans">ml_kmeans</a></code> <code><a href="ml_kmeans">ml_compute_cost</a></code> </p>
          </td>
          <td><p>Spark ML -- K-Means Clustering</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ml_lda">ml_lda</a></code> <code><a href="ml_lda">ml_describe_topics</a></code> <code><a href="ml_lda">ml_log_likelihood</a></code> <code><a href="ml_lda">ml_log_perplexity</a></code> </p>
          </td>
          <td><p>Spark ML -- Latent Dirichlet Allocation</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ml_linear_regression">ml_linear_regression</a></code> </p>
          </td>
          <td><p>Spark ML -- Linear Regression</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ml_logistic_regression">ml_logistic_regression</a></code> </p>
          </td>
          <td><p>Spark ML -- Logistic Regression</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ml_model_data">ml_model_data</a></code> </p>
          </td>
          <td><p>Extracts data associated with a Spark ML model</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ml_multilayer_perceptron_classifier">ml_multilayer_perceptron_classifier</a></code> <code><a href="ml_multilayer_perceptron_classifier">ml_multilayer_perceptron</a></code> </p>
          </td>
          <td><p>Spark ML -- Multilayer Perceptron</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ml_naive_bayes">ml_naive_bayes</a></code> </p>
          </td>
          <td><p>Spark ML -- Naive-Bayes</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ml_one_vs_rest">ml_one_vs_rest</a></code> </p>
          </td>
          <td><p>Spark ML -- OneVsRest</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ft_pca">ft_pca</a></code> <code><a href="ft_pca">ml_pca</a></code> </p>
          </td>
          <td><p>Feature Tranformation -- PCA (Estimator)</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ml_random_forest">ml_random_forest_classifier</a></code> <code><a href="ml_random_forest">ml_random_forest</a></code> <code><a href="ml_random_forest">ml_random_forest_regressor</a></code> </p>
          </td>
          <td><p>Spark ML -- Random Forest</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ml_aft_survival_regression">ml_aft_survival_regression</a></code> <code><a href="ml_aft_survival_regression">ml_survival_regression</a></code> </p>
          </td>
          <td><p>Spark ML -- Survival Regression</p></td>
        </tr>
      </tbody><tbody>
        <tr>
          <th colspan="2">
            <h2 id="section-spark-feature-transformers" class="hasAnchor"><a href="#section-spark-feature-transformers" class="anchor"></a>Spark Feature Transformers</h2>
            <p class="section-desc"></p>
          </th>
        </tr>
        <tr>
          <!--  -->
          <td>
            <p><code><a href="ft_binarizer">ft_binarizer</a></code> </p>
          </td>
          <td><p>Feature Transformation -- Binarizer (Transformer)</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ft_bucketizer">ft_bucketizer</a></code> </p>
          </td>
          <td><p>Feature Transformation -- Bucketizer (Transformer)</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ft_count_vectorizer">ft_count_vectorizer</a></code> </p>
          </td>
          <td><p>Feature Tranformation -- CountVectorizer (Estimator)</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ft_dct">ft_dct</a></code> <code><a href="ft_dct">ft_discrete_cosine_transform</a></code> </p>
          </td>
          <td><p>Feature Transformation -- Discrete Cosine Transform (DCT) (Transformer)</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ft_elementwise_product">ft_elementwise_product</a></code> </p>
          </td>
          <td><p>Feature Transformation -- ElementwiseProduct (Transformer)</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ft_index_to_string">ft_index_to_string</a></code> </p>
          </td>
          <td><p>Feature Transformation -- IndexToString (Transformer)</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ft_one_hot_encoder">ft_one_hot_encoder</a></code> </p>
          </td>
          <td><p>Feature Transformation -- OneHotEncoder (Transformer)</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ft_quantile_discretizer">ft_quantile_discretizer</a></code> </p>
          </td>
          <td><p>Feature Transformation -- QuantileDiscretizer (Estimator)</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sql-transformer">ft_sql_transformer</a></code> <code><a href="sql-transformer">ft_dplyr_transformer</a></code> </p>
          </td>
          <td><p>Feature Transformation -- SQLTransformer</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ft_string_indexer">ft_string_indexer</a></code> <code><a href="ft_string_indexer">ml_labels</a></code> </p>
          </td>
          <td><p>Feature Tranformation -- StringIndexer (Estimator)</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ft_vector_assembler">ft_vector_assembler</a></code> </p>
          </td>
          <td><p>Feature Transformation -- VectorAssembler (Transformer)</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ft_tokenizer">ft_tokenizer</a></code> </p>
          </td>
          <td><p>Feature Tranformation -- Tokenizer (Transformer)</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ft_regex_tokenizer">ft_regex_tokenizer</a></code> </p>
          </td>
          <td><p>Feature Tranformation -- RegexTokenizer (Transformer)</p></td>
        </tr>
      </tbody><tbody>
        <tr>
          <th colspan="2">
            <h2 id="section-spark-machine-learning-utilities" class="hasAnchor"><a href="#section-spark-machine-learning-utilities" class="anchor"></a>Spark Machine Learning Utilities</h2>
            <p class="section-desc"></p>
          </th>
        </tr>
        <tr>
          <!--  -->
          <td>
            <p><code><a href="ml_evaluator">ml_binary_classification_evaluator</a></code> <code><a href="ml_evaluator">ml_binary_classification_eval</a></code> <code><a href="ml_evaluator">ml_multiclass_classification_evaluator</a></code> <code><a href="ml_evaluator">ml_classification_eval</a></code> <code><a href="ml_evaluator">ml_regression_evaluator</a></code> </p>
          </td>
          <td><p>Spark ML - Evaluators</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ml_tree_feature_importance">ml_tree_feature_importance</a></code> </p>
          </td>
          <td><p>Spark ML - Feature Importance for Tree Models</p></td>
        </tr>
      </tbody><tbody>
        <tr>
          <th colspan="2">
            <h2 id="section-extensions" class="hasAnchor"><a href="#section-extensions" class="anchor"></a>Extensions</h2>
            <p class="section-desc"></p>
          </th>
        </tr>
        <tr>
          <!--  -->
          <td>
            <p><code><a href="compile_package_jars">compile_package_jars</a></code> </p>
          </td>
          <td><p>Compile Scala sources into a Java Archive (jar)</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="connection_config">connection_config</a></code> </p>
          </td>
          <td><p>Read configuration values for a connection</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="download_scalac">download_scalac</a></code> </p>
          </td>
          <td><p>Downloads default Scala Compilers</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="find_scalac">find_scalac</a></code> </p>
          </td>
          <td><p>Discover the Scala Compiler</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark-api">spark_context</a></code> <code><a href="spark-api">java_context</a></code> <code><a href="spark-api">hive_context</a></code> <code><a href="spark-api">spark_session</a></code> </p>
          </td>
          <td><p>Access the Spark API</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="hive_context_config">hive_context_config</a></code> </p>
          </td>
          <td><p>Runtime configuration interface for Hive</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="invoke">invoke</a></code> <code><a href="invoke">invoke_static</a></code> <code><a href="invoke">invoke_new</a></code> </p>
          </td>
          <td><p>Invoke a Method on a JVM Object</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="register_extension">register_extension</a></code> <code><a href="register_extension">registered_extensions</a></code> </p>
          </td>
          <td><p>Register a Package that Implements a Spark Extension</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_compilation_spec">spark_compilation_spec</a></code> </p>
          </td>
          <td><p>Define a Spark Compilation Specification</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_default_compilation_spec">spark_default_compilation_spec</a></code> </p>
          </td>
          <td><p>Default Compilation Specification for Spark Extensions</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_connection">spark_connection</a></code> </p>
          </td>
          <td><p>Retrieve the Spark Connection Associated with an R Object</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_context_config">spark_context_config</a></code> </p>
          </td>
          <td><p>Runtime configuration interface for Spark.</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_dataframe">spark_dataframe</a></code> </p>
          </td>
          <td><p>Retrieve a Spark DataFrame</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_dependency">spark_dependency</a></code> </p>
          </td>
          <td><p>Define a Spark dependency</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_home_set">spark_home_set</a></code> </p>
          </td>
          <td><p>Set the SPARK_HOME environment variable</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_jobj">spark_jobj</a></code> </p>
          </td>
          <td><p>Retrieve a Spark JVM Object Reference</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_version">spark_version</a></code> </p>
          </td>
          <td><p>Get the Spark Version Associated with a Spark Connection</p></td>
        </tr>
      </tbody><tbody>
        <tr>
          <th colspan="2">
            <h2 id="section-distributed-computing" class="hasAnchor"><a href="#section-distributed-computing" class="anchor"></a>Distributed Computing</h2>
            <p class="section-desc"></p>
          </th>
        </tr>
        <tr>
          <!--  -->
          <td>
            <p><code><a href="spark_apply">spark_apply</a></code> </p>
          </td>
          <td><p>Apply an R Function in Spark</p></td>
        </tr>
      </tbody>
      </table>

  </div>

  </div>


