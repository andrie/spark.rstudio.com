---
title: "Manage Spark Connections"
aliases:
  - reference/sparklyr/latest/spark-connections.html
  - reference/spark-connections.html
---

    <div class="doc-page">

    <div class="doc-page-index">
    <ul data-gumshoe>
    <li><a href="#arguments">Arguments</a></li>
        
    <li><a href="#examples">Examples</a></li>
    </ul>
    </div>

    <div class="doc-page-body">

    
    <p>These routines allow you to manage your connections to Spark.</p>
    

    <div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class='fu'>spark_connect</span>(<span class='no'>master</span>, <span class='kw'>spark_home</span> <span class='kw'>=</span> <span class='fu'>Sys.getenv</span>(<span class='st'>"SPARK_HOME"</span>),
  <span class='kw'>method</span> <span class='kw'>=</span> <span class='fu'>c</span>(<span class='st'>"shell"</span>, <span class='st'>"livy"</span>, <span class='st'>"databricks"</span>, <span class='st'>"test"</span>), <span class='kw'>app_name</span> <span class='kw'>=</span> <span class='st'>"sparklyr"</span>,
  <span class='kw'>version</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>hadoop_version</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>config</span> <span class='kw'>=</span> <span class='fu'><a href='spark_config.html'>spark_config</a></span>(),
  <span class='kw'>extensions</span> <span class='kw'>=</span> <span class='kw pkg'>sparklyr</span><span class='kw ns'>::</span><span class='fu'><a href='http://www.rdocumentation.org/packages/sparklyr/topics/register_extension'>registered_extensions</a></span>(), <span class='no'>...</span>)

<span class='fu'>spark_connection_is_open</span>(<span class='no'>sc</span>)

<span class='fu'>spark_disconnect</span>(<span class='no'>sc</span>, <span class='no'>...</span>)

<span class='fu'>spark_disconnect_all</span>()</code></pre></div>
    
    <h2 id="arguments">Arguments</h2>
    <table class="ref-arguments">

    <colgroup>
      <col class="name" />
      <col class="desc" />
    </colgroup>

    <tr>
      <td>master</td>
      <td><p>Spark cluster url to connect to. Use <code>"local"</code> to
connect to a local instance of Spark installed via
<code><a href='spark_install.html'>spark_install</a></code>.</p></td>
    </tr>
    <tr>
      <td>spark_home</td>
      <td><p>The path to a Spark installation. Defaults to the path
provided by the <code>SPARK_HOME</code> environment variable. If
<code>SPARK_HOME</code> is defined, it will be always be used unless the
<code>version</code> parameter is specified to force the use of a locally
installed version.</p></td>
    </tr>
    <tr>
      <td>method</td>
      <td><p>The method used to connect to Spark. Currently, only
<code>"shell"</code> is supported.</p></td>
    </tr>
    <tr>
      <td>app_name</td>
      <td><p>The application name to be used while running in the Spark
cluster.</p></td>
    </tr>
    <tr>
      <td>version</td>
      <td><p>The version of Spark to use. Only applicable to
<code>"local"</code> Spark connections.</p></td>
    </tr>
    <tr>
      <td>hadoop_version</td>
      <td><p>The version of Hadoop to use. Only applicable to
<code>"local"</code> Spark connections.</p></td>
    </tr>
    <tr>
      <td>config</td>
      <td><p>Custom configuration for the generated Spark connection. See
<code><a href='spark_config.html'>spark_config</a></code> for details.</p></td>
    </tr>
    <tr>
      <td>extensions</td>
      <td><p>Extension packages to enable for this connection. By
default, all packages enabled through the use of
<code><a href='register_extension.html'>sparklyr::register_extension</a></code> will be passed here.</p></td>
    </tr>
    <tr>
      <td>...</td>
      <td><p>Optional arguments; currently unused.</p></td>
    </tr>
    <tr>
      <td>sc</td>
      <td><p>A <code>spark_connection</code>.</p></td>
    </tr>
    </table>
    

    <h2 id="examples">Examples</h2>
    <div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><div class='input'>
<span class='no'>sc</span> <span class='kw'>&lt;-</span> <span class='fu'>spark_connect</span>(<span class='kw'>master</span> <span class='kw'>=</span> <span class='st'>"spark://HOST:PORT"</span>)</div><div class='output co'>#&gt; <span class='error'>Error in spark_connect(master = "spark://HOST:PORT"): could not find function "spark_connect"</span></div><div class='input'><span class='fu'><a href='connection_is_open.html'>connection_is_open</a></span>(<span class='no'>sc</span>)</div><div class='output co'>#&gt; <span class='error'>Error in connection_is_open(sc): could not find function "connection_is_open"</span></div><div class='input'>
<span class='fu'>spark_disconnect</span>(<span class='no'>sc</span>)</div><div class='output co'>#&gt; <span class='error'>Error in spark_disconnect(sc): could not find function "spark_disconnect"</span></div><div class='input'>
</div></code></pre></div>
    </div>

    </div>

